import './styles.css'

import { Head, Image, Appear, Notes, Invert, Split } from "mdx-deck"

import { CodeSurfer, CodeSurferColumns, Step } from "code-surfer"
import { shadesOfPurple } from "@code-surfer/themes"
import theme from './theme'

import thanos from './static/thanos_logo.svg'
import prometheus from './static/prometheus_logo.svg'
import redhat from './static/red_hat_logo.png'

export const themes = [
	shadesOfPurple,
	theme,
];

<Head>
	<title>Are you testing your Observability?</title>
</Head>

<CodeSurfer>

```go
	talks_total{title="    Are you testing your Observability?    "} 2
	talks_total{subtitle="       --- Metrics Edition ---       "} 2



	talks_total{conference="FOSDEM", when="02.02.2020", where="Brussel"} 1
```

</CodeSurfer>

<Notes>

Hello everyone!

We are extremely excited to be here in FOSDEM conference, and be able to speak about the topic we love Observability.

We hope our talk will be very inspiring and actionable for you.
This is because at the end of this talk we would like you to know 3 THINGS:

* Why instrumenting backend applications with actionable metrics is essential
* How to instrument your service quickly for Prometheus metric system to use
* And last but not the least: What are the common mistakes you should avoid, mistakes that
we seen a lot during our work with Go and metrics in the amazing (but sometimes WILD) OPEN SOURCE WORLD.

But before that: Short introduction!

</Notes>

---

import bartek from './static/bartek.jpeg'
import kemal from './static/kemal.jpeg'
import twitter from './static/twitter.png'
import github from './static/github.png'

<div style="width: 100%; height: 50%; overflow: auto;">
<img src={bartek} style="height: 90%; float: left; margin-top: 20px; padding: 0 20px 0 20px"/>

#### Bartek Plotka

<div style="font-size: 50%">
Principal Software Engineer @ Red Hat<br/>
OpenShift Monitoring Team<br/>
Prometheus and Thanos Maintainer<br/><br/>

<img src={twitter} style="height: 40px; width: 40px;"/> <img src={github} style="height: 40px; width: 40px;"/> @bwplotka
</div>
</div>

<div style="width: 100%; height: 50%; overflow: auto;">
<img src={kemal} style="height: 90%; float: left; margin-top: 20px; padding: 0 20px 0 20px"/>

#### Kemal Akkoyun

<div style="font-size: 50%">
Software Engineer @ Red Hat<br/>
OpenShift Monitoring Team<br/>
Thanos Contributor<br/><br/>

<img src={twitter} style="height:40px; width: 40px;"/> @kkakkoyun <span/>
<img src={github} style="height: 40px; width: 40px;"/> @kakkoyun
</div>
</div>

<Notes>

My name is Bartek Plotka, I am an engineer working at Red Hat in the Monitoring team, I love open source and solving problems
using Go.
I am part of Prometheus Team and I am a co-author of Thanos project, which is a durable system for scaling Prometheus.

With me there is Kemal...

Hello everyone, my name is Kemal Akkoyun. I am also a software engineer working with Bartek at Red Hat, for the OpenShift Monitoring team.
I'm also into everything related to Go, Prometheus and Kubernetes, so I love working with distributed systems and observability tools.

</Notes>

---

<div style="width: 100%; height: 50%; overflow: auto;">
<img src={prometheus} style="height: 50%; margin: auto; display: block; margin-top: 100px;" />
</div>

<div style="width: 100%; height: 50%; overflow: auto;">
<img src={thanos} style="height: 50%; margin: auto; display: block; margin-top: 100px;" />
</div>

<Notes>

Our job is focused on building scalable Observability solutions and platforms for OpenShift.
But also as one of the major part of our work is maintaining Prometheus and Thanos projects on a daily basis.
Those projects are focused on enabling monitoring via metrics for infrastructure, server side applications e.g
in microservices running on Kubernetes. While we work on enabling metrics from backend side, we also
are part of the client side of metrics, so applications that are being monitored. And this is the part we will be focusing
on today.

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Let's implement an HTTP L7 loadbalancer! ❤</h2>

---

import d01 from './static/d01.png'

<h2 style="text-align: center; margin: 0 10px 0 10px;">Because why not?</h2>

<Appear>
	<Image src={d01} size='contain'/>
</Appear>

<Notes>

Today we have a fun task! We will talk today about building loadbalancer. Kind of.

For demo purposes let's imagine we want to implement application level HTTP loadbalancer. Let's say in Go, but
programming language does not matter here.

1) So let's say we implemented transparent loadbalancer as presented in this diagram.
From high level design we have couple of Go components.

- Single HTTP server that implements ServeHTTP method, so handler via awesome ReverseProxy in standard httputil package.
- that ReverseProxy allows us to inject custom Transport, so RoundTripper interface.
- We inject there our load balancing RoundTipper implementation called lbtranport, which is internally
using then few components:
-- Discoverer which gives us targets to proxy / loadbalance request to
-- RoundRobinPicker which chooses right target to proxy user request to in FAIR, round robin manner, so: replica 1, 2,3, then again 1, 2, 3
-- And at the end it uses http.Transport to forward request to picked replica and proxy response back to the user.

</Notes>

---

import d02 from './static/d02.png'

<h2 style="text-align: center; margin: 0 10px 0 10px;">Wait... Anything missing?</h2>

<Image src={d02} size='contain'/>

<Notes>

This is great, it looks like this implementation should work.. but are we sure it's production ready?

So let's say we deploy couple of replicas of our loadbalancer in production in front of some microservice and let
it run for longer time.

As soon as it starts running, we hit /lb endpoint manually and we can see it works. So we are good, right?

Well...

</Notes>

---

import d03 from './static/d03.png'

<h2 style="text-align: center; margin: 0 10px 0 10px;">Wait... Anything missing?</h2>

<Image src={d03} size='contain'/>

<Notes>

Not necessarily. It works for me but are we sure loadbalancer works as expected all the time?
Does it actually work for all the users or only me? How many Bad Gateway Errors it was returning over time?
We can't really tell!

</Notes>

---

import d05 from './static/d05.png'

<h2 style="text-align: center; margin: 0 10px 0 10px;">Wait... Anything missing?</h2>

<Image src={d05} size='contain'/>

<Notes>

Is round robin picker, picking in round robin matter?
Is 1/3 of all requests actually going to replica 2? What's was the distribution of request over time? Was it fair?

</Notes>

---

import d06 from './static/d06.png'

<h2 style="text-align: center; margin: 0 10px 0 10px;">Wait... Anything missing?</h2>

<Image src={d06} size='contain'/>

<Notes>

What if users reports that the endpoint is slow: is it the backend that is slow?
Or is loadbalancing logic that is introducing the latency?

</Notes>

---

import d08 from './static/d08.png'

<h2 style="text-align: center; margin: 0 10px 0 10px;">Wait... Anything missing?</h2>

<Image src={d08} size='contain'/>

<Notes>

Finally what version of the loadbalancer we were running 2 days ago at 2pm? Maybe something was wrong back then and we
are not sure what version was actually rolled on Kubernetes...

</Notes>

---

import d09 from './static/d09.png'

<h2 style="text-align: center; margin: 0 10px 0 10px;"> We need Monitoring!</h2>

<Image src={d09} size='contain'/>


<Notes>

As you can see there are massive amount of questions that would be not answered when running the service like this on
production, without proper monitoring.

That's why in SRE book you will find monitoring as the foundation of any system, BEFORE even the system itself!

As you might be familiar, some monitoring signals we can introduce are: traces, logs and metrics.
Guess which signal will give us answer to our questions like distribution of requests or histogram of tail latency?

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Let's instrument our LB with Prometheus metrics!</h2>

<ul style="font-size: 80%; margin-top: 95px">
<Appear>
<li>Cheap</li>
<li>Near Real Time</li>
<li>Actionable (Alert-able)</li>
<div>
    <img src={prometheus} style="height: 50%; margin: auto; display: block; margin-top: 100px;" />
    <p>http://prometheus.io</p>
</div>
</Appear>
</ul>

<Notes>

Metrics, yup!

Metrics most likely give us the answers to our questions.
Answer that is in comparison to logs and traces:

1) CHEAPer to calculate
Near Real Time
Clear and Actionable, so you can alert on those.

In practice metrics should be the first item on monitoring list that you should do if you care to run your service reliably.

2) Why Prometheus though? Well I might be bias but Prometheus is currently one of the simplest and
cheapest option for collecting, storing and querying metrics as well as reliable alerting.
It is part of CNCF, fits for small solution as well as for bigger ones with help of cloud native projects like Thanos, Cortex, m3db and others

</Notes>

---

import d11 from './static/d11.png'

<h2 style="text-align: center; margin: 0 10px 0 10px;"> Let's instrument our LB with Prometheus metrics!</h2>

<Image src={d03} size='contain'/>

<Notes>

So.. how to add Prometheus metrics to our loadbalancer?
Let's say we want to answer for how many users our loadbalancer is actually responding working, and for how many
it returns error!

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;"> Let's instrument our LB with Prometheus metrics!</h2>

<Image src={d11} size='contain'/>

<Notes>

We can do that by incrementing some certain http_requests_total counter whenever a loadbalancing request occur
reporting method that was used, and HTTP status code that was returned.

We can introduce this metric really in few simple steps.

</Notes>

---

<CodeSurfer>

```go title="Server HTTP request counter" subtitle="Import Prometheus Go client package."

# You can find list of all available clients for 18 programming languages here:
# https://prometheus.io/docs/instrumenting/clientlibs/#client-libraries
import "github.com/prometheus/client_golang/prometheus"

```

```go 5,6,7,8,9,10 title="Server HTTP request counter" subtitle="Define counter."

import "github.com/prometheus/client_golang/prometheus"

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

```

```go title="Server HTTP request counter" subtitle="Instrument ServeHTTP function."

import "github.com/prometheus/client_golang/prometheus"

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

// Top level ServeHTTP handler.
func ServeHTTP(w http.ResponseWriter, r *http.Request) {
	statusRec := newStatusRecorder(w)
	next.ServeHTTP(statusRec, r)

	// Increment our counter with written status code and request method.
	serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)
}

```

```go 23 title="Server HTTP request counter" subtitle="Register our metric."

import "github.com/prometheus/client_golang/prometheus"

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

// Top level ServeHTTP handler.
func ServeHTTP(w http.ResponseWriter, r *http.Request) {
	statusRec := newStatusRecorder(w)
	next.ServeHTTP(statusRec, r)

	// Increment our counter with written status code and request method.
	serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)
}

func init() {
	prometheus.MustRegister(serverRequestsTotal)
}

```

```go title="Server HTTP request counter" subtitle="Add /metrics handler."

import "github.com/prometheus/client_golang/prometheus"

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

// Top level ServeHTTP handler.
func ServeHTTP(w http.ResponseWriter, r *http.Request) {
	statusRec := newStatusRecorder(w)
	next.ServeHTTP(statusRec, r)

	// Increment our counter with written status code and request method.
	serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)
}

func init() {
	prometheus.MustRegister(serverRequestsTotal)
}

mux := http.NewServeMux()
mux.Handle("/metrics", promhttp.Handler())
mux.Handle("/lb", ...)

// Other handlers...

srv := &http.Server{Handler: mux}

// Run server...

```

</CodeSurfer>

<Notes>

1) First of all we have to import Prometheus Go client library. We will show here an
example on how to add metric in Go language, but it's equally simple in other languages as well.
Similar libraries exists in 18 other programming languages.

However, we are focusing here on Go, since we are working with Go already 5-6years.

2) To add server HTTP metrics, As a next step we need to define variable for the our counter of requests. We pick a name, a description
and certain "labels" which will be our dimensions for this counter. Each unique value in any of those labels will
result in totally new series in Prometheus system.

3) Next step is to actually count our requests. Let's create a simple wrapper of http server which will increment
the counter with the status code that the server returned and requested method.

4) Something that is easy to forget is another step: The counter has to be registered somewhere in order
to be exposed for Prometheus. Let's do this once in `init` function and register it in GLOBAL
Prometheus registry.

Let's focus on what we accomplish by registering this metric. It's important for the next step which is

5) HTTP handler for metric page. It serves simple text page with all metrics.
Once we add that to our loadbalancer, our server  is correctly exposing the http_requests_total counter
we created to the outside world.

</Notes>

---

import graph_requests from './static/graph-requests.png'

<CodeSurfer>

```go 4,6 title="From code to graph" subtitle="We defined & instrumented our metric."

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

```

```go 4,6,10,13,14 title="From code to graph" subtitle="It is now exposed under /metrics."
var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

// Part of response from /metrics HTTP endpoint.
# HELP http_requests_total Tracks the number of HTTP requests.
# TYPE http_requests_total counter
http_requests_total{code="200", method="get"} 1089
http_requests_total{code="500", method="get"} 46

```

</CodeSurfer>

<Notes>

1) How we can now use our metric? As you remember we defined this metric like this and we increment it every HTTP request.
2) Loadbalancer now serves /metrics page which exposes our metrics in Prometheus supported text format.
As you can see each code and method are a separate counter, with mostly successes.

</Notes>

---

import d10 from './static/d10.png'

<h2 style="text-align: center; margin: 0px 10px 0 10px;">Prometheus can now collect metrics from our Loadbalancer</h2>

*Pulling e.g every 15 seconds*

<Image src={d12} size='contain'/>

<Notes>

We now can use running binary of Prometheus and point to the loadbalancer /metrics page. Prometheus then will
visit this page (which is called scrape) every given interval and collect all exposed metrics.

</Notes>

---

<h2 style="text-align: center; margin: 0px 10px 0 10px;">Graph: Prometheus UI</h2>

<img src={graph_requests} style="height: 70%; margin-top: 5%"/>

<Notes>

With that we can after some time, visit Prometheus UI where we can produce graphs. For example we can query
the number of requests per minute by code and method. We can see that per minute we have 120 requests in total,
with some small portion of those being error responses.

</Notes>

---

import pitfalls from './static/pitfall.gif'

<div>
    <h1 style="text-align: center; margin: 0px 10px 0 10px;">
        <img src={prometheus} style="width: 10%; margin-top: 5%"/>
        &nbsp;&nbsp;Pitfalls
    </h1>
</div>

<img src={pitfalls} style="height: 50%; margin-top: 5%"/>

<Notes>

So it looked easy right? And it is easy in most cases. However during this talk we would like
to present what we learnt during couple of years of developing and reviewing instrumentation code that
is meant to be run on production, in close but mainly in open source.

Together with Kemal wil go though a few less or more advanced issues we seen and how to resolve them.

</Notes>

---

import magic from './static/magic.gif'

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #1: Global Registry</h2>
<br/>
<br/>
<h6 style="text-align: center; margin: 0 10px 0 10px;">"magic is bad; global state is magic" by Peter Bourgon</h6>
<br/>
<img src={magic} style="height: 50%; margin-top: 5%"/>

<Notes>

First one! Globals.

There was a saying in amazing Peter Bourgon blog post "A theory of Modern Go": magic is bad; global state is magic.

This is very true also in case of Prometheus client, especially if you are instrumenting some library with metrics
that your project, or maybe anyone in open source is using. This Prometheus library especially Go one,
allows you to use globals for certain simplicity, however the usage of it leaked as a pattern which we really really want to obsolete.

So let's focus on where you can have magic in our metrics and what can go wrong, on example of our loadbalancer service.

</Notes>

---

<CodeSurfer>

```go title="Pitfall #1: Global Registry" subtitle="We have 2 global variables here."

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

func init() {
	prometheus.MustRegister(serverRequestsTotal)
}

// ...
// Increment our counter with written status code and request method.
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```diff 3,4,5,6,7,8 title="Pitfall #1: Global Registry" subtitle="Package-level metric variable."
```

```go 12[16:80] title="Pitfall #1: Global Registry" subtitle="and global DefaultRegisterer."

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

func init() {
	prometheus.DefaultRegisterer.MustRegister(serverRequestsTotal)
}

// ...
// Increment our counter with written status code and request method.
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go title="Pitfall #1: Global Registry" subtitle="What if another package will create metric with same name?"

// Inside package A:
var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

func init() {
	prometheus.MustRegister(serverRequestsTotal)
}

// Somewhere inside package X imported by your dependency:
func init() {
    // PANIC!
    // You cannot register same metric name twice.
    prometheus.MustRegister(prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Tracks the number of different HTTP requests.",
        }, []string{"code", "method"},
    ))
}

// ...
// Increment our counter with written status code and request method.
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go 15,16,17,18,19,20,21,22 title="Pitfall #1: Globals: No flexibility" subtitle="What if I have more handlers than one?"

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

func init() {
	prometheus.DefaultRegisterer.MustRegister(serverRequestsTotal)
}

// For endpoint /one:
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /two:
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /three:
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go title="Pitfall #1: Globals: No flexibility" subtitle="Nice, but for what handler?"

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

func init() {
	prometheus.DefaultRegisterer.MustRegister(serverRequestsTotal)
}

// For endpoint /one:
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /two:
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /three:
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

# HELP http_requests_total Tracks the number of HTTP requests.
# TYPE http_requests_total counter
http_requests_total{code="200", method="get"} 2445
http_requests_total{code="500", method="get"} 53

```

```go title="Pitfall #1: Getting rid of globals."

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

func init() {
	prometheus.DefaultRegisterer.MustRegister(serverRequestsTotal)
}

// For endpoint /one:
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /two:
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /three:
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go title="Pitfall #1: Getting rid of globals." subtitle="Introduce instance of metrics!"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics() *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	return m
}

func init() {
	prometheus.DefaultRegisterer.MustRegister(serverRequestsTotal)
}

// For endpoint /one:
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /two:
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /three:
serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go title="Pitfall #1: Getting rid of globals." subtitle="Create new instance of ServerMetrics."

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics() *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	return m
}

metrics := NewServerMetrics()

func init() {
	prometheus.DefaultRegisterer.MustRegister(metrics.requestsTotal)
}

// For endpoint /one:
metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /two:
metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /three:
metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go title="Pitfall #1: Getting rid of globals." subtitle="Register using Custom Registerer (composition!)"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

reg := prometheus.NewRegistry()
metrics := NewServerMetrics(reg)

// For endpoint /one:
metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /two:
metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /three:
metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

``` go title="Pitfall #1: Getting rid of globals." subtitle="Is it ok now?"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

reg := prometheus.NewRegistry()

// This will panic, because we register same metric 3 times...
metrics1 := NewServerMetrics(reg)
metrics2 := NewServerMetrics(reg)
metrics3 := NewServerMetrics(reg)

// For endpoint /one:
metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /two:
metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /three:
metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go 23,26,29 title="Pitfall #1: Getting rid of globals." subtitle="We can wrap register to inject label."

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

reg := prometheus.NewRegistry()

metrics1 := NewServerMetrics(
prometheus.WrapWithLabels(prometheus.Labels{"handler":"/one"}, reg),
)
metrics2 := NewServerMetrics(
prometheus.WrapWithLabels(prometheus.Labels{"handler":"/two"}, reg),
)
metrics3 := NewServerMetrics(
prometheus.WrapWithLabels(prometheus.Labels{"handler":"/three"}, reg),
)

// For endpoint /one:
metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /two:
metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /three:
metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go title="Pitfall #1: Getting rid of globals." subtitle="We can have request counter per handler (:"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

reg := prometheus.NewRegistry()

metrics1 := NewServerMetrics(
prometheus.WrapWithLabels(prometheus.Labels{"handler":"/one"}, reg),
)
metrics2 := NewServerMetrics(
prometheus.WrapWithLabels(prometheus.Labels{"handler":"/two"}, reg),
)
metrics3 := NewServerMetrics(
prometheus.WrapWithLabels(prometheus.Labels{"handler":"/three"}, reg),
)

// For endpoint /one:
metrics1.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /two:
metrics2.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

// For endpoint /three:
metrics3.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

# HELP http_requests_total Tracks the number of HTTP requests.
# TYPE http_requests_total counter
http_requests_total{handler="/one", code="200", method="get"} 1445
http_requests_total{handler="/one", code="500", method="get"} 23
http_requests_total{handler="/two", code="200", method="get"} 445
http_requests_total{handler="/two", code="500", method="get"} 0
http_requests_total{handler="/three", code="200", method="get"} 645
http_requests_total{handler="/three", code="500", method="get"} 40

```

</CodeSurfer>

<Notes>

1) Let's take our example or http requests_total metric. We have 2 global states here.

2) As you can see metric is a global, package level variable. We register it once per package import as well.

3) Second place of global state is MustRegister which is actually hiding a Global DefaultRegisterer, so
we are registering out metric in global state of Prometheus library.

Now what's the issue here? Why is that problematic?

4) First problem is well magic.. If another package you just import, or you dependency imports registers a metrics
with the same name your application will crash at start.
Even worse the stacktrace will give you the clue where the second register happened but nothing about first one!
We have seen a lot of those problems, so please don't use globals (:

5) Second issue is lack of flexibility! What if you have more than one handler, more than one endpoint?

6) As you can see the insight you gain is pretty limited as the requests are counted per all endpoints. I can't tell
what's the error rate for /three endpoint for example.

Let's try to fix this!

7) And by fixing I mean removing globals!

8) Let's replace global variable with some struct that you can instantiate. It will have constructor that will create
our counter.

9) Now you can create such object and use it everywhere.

10) To eliminate last global behind registering, let's inject custom register into our constructor and instantiate
our own registry which we control in explicit way during our application lifetime!

11) Now what if we try to have different metrics for each handler? It will panic again, but there is nice solution
to that and since we are in control let's apply it.

12) Prometheus allows wrapping registry with custom prefix or labels, so we can inject handler label for each endpoint.

13) Now we have our metrics nicely grouped by handler as well, so we have additional crucial insight on what's
the number of requests per endpoint as well.

</Notes>

---

import testing from './static/testing.gif'

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #2: No Tests For Metrics</h2>
<br/>
<br/>
<img src={testing} style="height: 50%; margin-top: 5%"/>

<Notes>

This is something I am really passionated about.
Metrics and other observability signals like e.g tracing, logs and profiles are rarely tested.

Who is asserting in unit test if log or trace was produced for certain even and if it has certain message.
It's not always true but logs are usually used by humans so there is no point in checking exact message.

With metrics in my opinion it's totally different story. They has to be tested. Let me explain in second why.

</Notes>

---

import d12 from './static/d12.png'

<h2 style="text-align: center; margin: 0 10px 0 10px;"> Let's test our LB!</h2>

<Image src={d11} size='contain'/>

<Notes>

So let's take our loadbalancer, again and newly added HTTP request total counter.
We are solid 10x developers right, so we want to test our code, so we wrote
some unit test!

</Notes>

---

import d13 from './static/d13.png'

<h2 style="text-align: center; margin: 0px 10px 0 10px;">Unit testing lbtransport.RoundTripper</h2>

<Image src={d13} size='contain'/>

<Notes>

And yes, it involves Mocking the Discoverer and Round Robin Picker.
Mocking our Replicas for some case like, for example all replica being down
and not available.

And sending few mocked HTTP requests against that.

</Notes>

---

import d14 from './static/d14.png'

<h2 style="text-align: center; margin: 0px 10px 0 10px;">Unit testing lbtransport.RoundTripper</h2>

<Image src={d14} size='contain'/>

<Notes>

So we run this test, we run 3 request, we assert that response is 502, so Bad Gateway, we could
not loadabalance - expected error case that can happen.

And we are good, we can test different cases in similar way, all passed and we are fine, right?
</Notes>

---

<CodeSurfer>

```go title="Pitfall #2: Not testing" subtitle="How it looks in Go code?"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

```

```go title="Pitfall #2: Not testing" subtitle="Let's verify correct metric instrumentation!"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

func TestLoadbalancer(t *testing.T) {
    // ...
    lb := NewLoadbalancingTransport(nil, mockedDiscovery, mockedPicker, mockedTransport)
​
}

```

```go title="Pitfall #2: Not testing" subtitle="Let's verify correct metric instrumentation!"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

func TestLoadbalancer(t *testing.T) {
    // ...
    lb := NewLoadbalancingTransport(nil, mockedDiscovery, mockedPicker, mockedTransport)
​
    // Send 3x HTTP requests.
    rec1 := httptest.NewRecorder()
    lb.ServeHTTP(rec1, httptest.NewRequest("GET", "http://mocked", nil))
    rec2 := httptest.NewRecorder()
    lb.ServeHTTP(rec2, httptest.NewRequest("GET", "http://mocked", nil))
    rec3 := httptest.NewRecorder()
    lb.ServeHTTP(rec3, httptest.NewRequest("GET", "http://mocked", nil))

}

```

```go title="Pitfall #2: Not testing" subtitle="Let's verify correct metric instrumentation!"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

func TestLoadbalancer(t *testing.T) {
    // ...
    lb := NewLoadbalancingTransport(nil, mockedDiscovery, mockedPicker, mockedTransport)
​
    // Send 3x HTTP requests.
    rec1 := httptest.NewRecorder()
    lb.ServeHTTP(rec1, httptest.NewRequest("GET", "http://mocked", nil))
    rec2 := httptest.NewRecorder()
    lb.ServeHTTP(rec2, httptest.NewRequest("GET", "http://mocked", nil))
    rec3 := httptest.NewRecorder()
    lb.ServeHTTP(rec3, httptest.NewRequest("GET", "http://mocked", nil))

    // Assert 3x responses with 502 status code.
    testutil.Equals(t, 502, rec.Code)
    testutil.Equals(t, 502, rec.Code)
    testutil.Equals(t, 502, rec.Code)

}

```

</CodeSurfer>

<Notes>

1) Ok, so let's see how it looks in our Go code! And Let's take our http requests example.
2) We then create a unit test, Send 3 HTTP requests, Assert 3x responses 502 status code.. and all good!

</Notes>

---

import d15 from './static/d15.png'

<h2 style="text-align: center; margin: 0px 10px 0 10px;">Do we verified everything?</h2>

<Image src={d15} size='contain'/>

<Notes>

Nice, but what if did not instrument our metric correctly, right?

For example we made a bug while incrementing a http request total metric, and we always
instrument it with 200 HTTP request code.

Now what you can see.. our unit test passed just fine, however the actual metric exposed
to Prometheus shows incorrect information.

You can think that this is not a big deal, just some analytics will mislead. Well it is actually
serious.

</Notes>

---

<CodeSurfer>

```go title="Pitfall #2: Not testing" subtitle="Alert for too many errors will be missed."

alert: HttpTooMany502Errors
  expr: |
    sum(rate(http_requests_total{status="502"}[1m])) /
      sum(rate(http_requests_total[1m])) * 100 > 5
  for: 5m
  labels:
    severity: error
  annotations:
    summary: "HTTP errors 502 (instance {{ $labels.instance }})"
    description: |
      "Too many HTTP requests with status 502 (> 5%)\n  VALUE = {{ $value }}\n
      LABELS: {{ $labels }}"

```

</CodeSurfer>

<Notes>

Imagine this alert, it's one the...

</Notes>

---

import d16 from './static/d16.png'

<h2 style="text-align: center; margin: 0px 10px 0 10px;">Let's verify correct metric instrumentation!</h2>

<Image src={d16} size='contain'/>

<Notes>

What we need to do, is actually verify more - so check if we instrumented out metric well!

</Notes>

---

<CodeSurfer>

```go title="Pitfall #2: Not testing" subtitle="Let's verify correct metric instrumentation!"

func TestLoadbalancer(t *testing.T) {
    // ...
    lb := NewLoadbalancingTransport(nil, mockedDiscovery, mockedPicker, mockedTransport)
​
    // Send 3x HTTP requests.
    rec1 := httptest.NewRecorder()
    lb.ServeHTTP(rec1, httptest.NewRequest("GET", "http://mocked", nil))
    rec2 := httptest.NewRecorder()
    lb.ServeHTTP(rec2, httptest.NewRequest("GET", "http://mocked", nil))
    rec3 := httptest.NewRecorder()
    lb.ServeHTTP(rec3, httptest.NewRequest("GET", "http://mocked", nil))

    // Assert 3x responses with 502 status code.
    testutil.Equals(t, 502, rec.Code)
    testutil.Equals(t, 502, rec.Code)
    testutil.Equals(t, 502, rec.Code)

}

```

```go title="Pitfall #2: Not testing" subtitle="Let's verify correct metric instrumentation!"

import (
    promtestutils "github.com/prometheus/client_golang/prometheus/testutil"
)

func TestLoadbalancer(t *testing.T) {
    // ...
    lb := NewLoadbalancingTransport(nil, mockedDiscovery, mockedPicker, mockedTransport)
​
    // Assert 0 cardinality for http_requests_total{}
    // No requests, no metric should be exposed.
	testutil.Equals(t, 0, promtestutil.CollectAndCount(lb.metrics.requestsTotal))

    // Send 3x HTTP requests.
    rec1 := httptest.NewRecorder()
    lb.ServeHTTP(rec1, httptest.NewRequest("GET", "http://mocked", nil))
    rec2 := httptest.NewRecorder()
    lb.ServeHTTP(rec2, httptest.NewRequest("GET", "http://mocked", nil))
    rec3 := httptest.NewRecorder()
    lb.ServeHTTP(rec3, httptest.NewRequest("GET", "http://mocked", nil))

    // Assert 3x responses with 502 status code.
    testutil.Equals(t, 502, rec.Code)
    testutil.Equals(t, 502, rec.Code)
    testutil.Equals(t, 502, rec.Code)

}

```

```go title="Pitfall #2: Not testing" subtitle="Let's verify correct metric instrumentation!"

import (
    promtestutils "github.com/prometheus/client_golang/prometheus/testutil"
)

func TestLoadbalancer(t *testing.T) {
    // ...
    lb := NewLoadbalancingTransport(nil, mockedDiscovery, mockedPicker, mockedTransport)
​
    // Assert 0 cardinality for http_requests_total{}
    // No requests, no metric should be exposed.
	testutil.Equals(t, 0, promtestutil.CollectAndCount(lb.metrics.requestsTotal))

    // Send 3x HTTP requests.
    rec1 := httptest.NewRecorder()
    lb.ServeHTTP(rec1, httptest.NewRequest("GET", "http://mocked", nil))
    rec2 := httptest.NewRecorder()
    lb.ServeHTTP(rec2, httptest.NewRequest("GET", "http://mocked", nil))
    rec3 := httptest.NewRecorder()
    lb.ServeHTTP(rec3, httptest.NewRequest("GET", "http://mocked", nil))

    // Assert 3x responses with 502 status code.
    testutil.Equals(t, 502, rec.Code)
    testutil.Equals(t, 502, rec.Code)
    testutil.Equals(t, 502, rec.Code)

    // Assert 1 cardinality for http_requests_total{} .
    testutil.Equals(t, 1, promtestutil.CollectAndCount(lb.metrics.requestsTotal))

}

```

```go title="Pitfall #2: Not testing" subtitle="Let's verify correct metric instrumentation!"

import (
    promtestutils "github.com/prometheus/client_golang/prometheus/testutil"
)

func TestLoadbalancer(t *testing.T) {
    // ...
    lb := NewLoadbalancingTransport(nil, mockedDiscovery, mockedPicker, mockedTransport)
​
    // Assert 0 cardinality for http_requests_total{}
    // No requests, no metric should be exposed.
	testutil.Equals(t, 0, promtestutil.CollectAndCount(lb.metrics.requestsTotal))

    // Send 3x HTTP requests.
    rec1 := httptest.NewRecorder()
    lb.ServeHTTP(rec1, httptest.NewRequest("GET", "http://mocked", nil))
    rec2 := httptest.NewRecorder()
    lb.ServeHTTP(rec2, httptest.NewRequest("GET", "http://mocked", nil))
    rec3 := httptest.NewRecorder()
    lb.ServeHTTP(rec3, httptest.NewRequest("GET", "http://mocked", nil))

    // Assert 3x responses with 502 status code.
    testutil.Equals(t, 502, rec.Code)
    testutil.Equals(t, 502, rec.Code)
    testutil.Equals(t, 502, rec.Code)

    // Assert 1 cardinality for http_requests_total{} .
    testutil.Equals(t, 1, promtestutil.CollectAndCount(lb.metrics.requestsTotal))

    // Assert http_requests_total{code="502", method="get"} == 3 .
    testutil.Equals(
        t,
        3,
        promtestutil.ToFloat64(metrics.requestsTotal.WithLabelValues("502", "get")),
     )
}

```

```go title="Pitfall #2: Not testing" subtitle="Such unit test will detect the problem!"

import (
    promtestutils "github.com/prometheus/client_golang/prometheus/testutil"
)

func TestLoadbalancer(t *testing.T) {
    // ...
    lb := NewLoadbalancingTransport(nil, mockedDiscovery, mockedPicker, mockedTransport)
​
    // Assert 0 cardinality for http_requests_total{}
    // No requests, no metric should be exposed.
	testutil.Equals(t, 0, promtestutil.CollectAndCount(lb.metrics.requestsTotal))

    // Send 3x HTTP requests.
    rec1 := httptest.NewRecorder()
    lb.ServeHTTP(rec1, httptest.NewRequest("GET", "http://mocked", nil))
    rec2 := httptest.NewRecorder()
    lb.ServeHTTP(rec2, httptest.NewRequest("GET", "http://mocked", nil))
    rec3 := httptest.NewRecorder()
    lb.ServeHTTP(rec3, httptest.NewRequest("GET", "http://mocked", nil))

    // Assert 3x responses with 502 status code.
    testutil.Equals(t, 502, rec.Code)
    testutil.Equals(t, 502, rec.Code)
    testutil.Equals(t, 502, rec.Code)

    // Assert 1 cardinality for http_requests_total{} .
    testutil.Equals(t, 1, promtestutil.CollectAndCount(lb.metrics.requestsTotal))

    // Assert http_requests_total{code="502", method="get"} == 3 .
    // === RUN   TestLoadbalancer/#00
    //       --- FAIL: TestLoadbalancer/#00 (0.00s)
    //           transport_test.go:190:
    //
    //               exp: 1
    //
    //               got: 0
    //   FAIL
    //
    testutil.Equals(
        t,
        3,
        promtestutil.ToFloat64(metrics.requestsTotal.WithLabelValues("502", "get")),
     )
}

```

</CodeSurfer>

<Notes>

1)

We really recommend to extend your normal tests with metrics assertion for all your crucial metrics.

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #3: Lack of Consistency</h2>
<br/>
<br/>
<Appear>

<h4 style="text-align: center; margin: 0 10px 0 10px;">The Four Golden Signals, USE method, RED method etc...</h4>

<div>
<br/>
<br/>
<ul>
<li><span style="color: red">R</span>: Requests per second (saturation).</li>
<li><span style="color: red">E</span>: Errors per second.</li>
<li><span style="color: red">D</span>: Duration (tail latency).</li>
</ul>
</div>
</Appear>

<Notes>

KEMAL

TODO: Terraform for yourself

Lack of consistency. So there are some useful methods on what metrics you should define
for your system, usually a web servers. The four golden signals from SRE book, USE method, RED method.

There are two advantages to follow them:

- This helps to be sure you have main signals upfront of potential debugging or alerting needs.
- It helps to reuse common alerts, recording rules and dashboards. e.g mixin project. If you are following
the same method.

1) Let's focus on one method. For example RED: R stands for rps, E for err, D for dur.

</Notes>

---

<CodeSurfer>

```go title="Pitfall #3: Lack of consistency" subtitle="Does this satisfy RED method?"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

```

```diff 11,13 title="Pitfall #3: Lack of consistency" subtitle="R = Requests"
```

```diff 13[25:30] title="Pitfall #3: Lack of consistency" subtitle='E = Errors (code = "5..")'
```

```diff 10[1:2] title="Pitfall #3: Lack of consistency" subtitle="D = Duration is Missing!"
```

```go 4,16,17,18,19,20,21,22,23,24,31,32 title="Pitfall #3: Consistency" subtitle="Red method satisfied"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
        requestDuration: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name:    "http_request_duration_seconds",
                Help:    "Tracks the latencies for HTTP requests.",
                Buckets: []float64{0.001, 0.01, 0.1, 0.3, 0.6, 1, 3, 6, 9, 20, 30, 60, 90, 120},
            },
            []string{"code", "method"},
        ),
	}
	reg.MustRegister(m.requestsTotal, m.requestDuration)
	return ins
}

// Top level ServeHTTP handler.
func ServeHTTP(w http.ResponseWriter, r *http.Request) {
	start := time.Now()
	defer metrics.requestDuration.WithLabelValues(statusRec.Status(), r.Method)).Observe(time.Since(start))

	statusRec := newStatusRecorder(w)
	next.ServeHTTP(statusRec, r)

	// Increment our counter with written status code and request method.
	metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)
}

```

</CodeSurfer>

<Notes>

KEMAL

TODO: Terraform for yourself

1) Does our Server Metrics satisfy RED method?
2) We have certainly requests
3) Errors when code is not 200
4) But duration is missing!
5) To satisfy RED method we can easily add histogram which will observe latency of the whole service.
Now our loadbalancer has consistent metrics and can reuse RED dashboards, alerts and recording rule which
is awesome.

Now I will pass mic to Kemal.

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #4: Naming - Not conforming naming convention</h2>

<Notes>

KEMAL

One of the most common pitfall is of course about naming!

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;"> There is an official documentation on naming conventions</h2>

<div style="font-size: 80%; text-align: center">
	<h6><a>https://prometheus.io/docs/practices/naming/#metric-and-label-naming</a></h6>
</div>

<Notes>

KEMAL

There is official Prometheus metric and label name convention!
Check it out, it's really helpful.

</Notes>

---

<Notes>

KEMAL

A couple of bullet points to highlight.

1)
Names should have a suffix describing the unit, in plural form.

2)
An accumulating counter has *_total* as a suffix, in addition to the unit if applicable.
With new OpenMetrics standards this will become mandatory.

3)
Put _info suffix at the end for a pseudo-metric that provides metadata about the running binary.

</Notes>

<CodeSurfer>

```go title="Pitfall #4: Naming - Not conforming naming convention"
```

```go title="Pitfall #4: Naming - Not conforming naming convention" subtitle="Names should have a suffix describing the unit."

http_request_duration_seconds
node_memory_usage_bytes

```

```go title="Pitfall #4: Naming - Not conforming naming convention" subtitle="Counter names have *_total* as a suffix."

http_request_duration_seconds
node_memory_usage_bytes

http_requests_total
process_cpu_seconds_total

```

```go title="Pitfall #4: Naming - Not conforming naming convention" subtitle="_info suffix for metadata metric names."

http_request_duration_seconds
node_memory_usage_bytes

http_requests_total
process_cpu_seconds_total

build_info

```

</CodeSurfer>

---

<Notes>

KEMAL

There is important aspect of naming as well: its stability.

1)
Let's say we have a metric that aggregates total number of http requests that we handle which also records status codes.

2)
Let's build an alert using it.

3)
At something, for whaetever reason you decide to change your metric and you add _protocol_ in the name.

4)
This alert will never fire but also will not fail!
Rename can cause issues like this in Alerts, Recording rules, Dashboards and more..

</Notes>

<CodeSurfer>

```go title="Pitfall #4: Naming - Stability"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

```

```go title="Pitfall #4: Naming - Stability" subtitle="Let's say we alert on too many 5xx responses."

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

alert: HttpToMany502Errors
  expr: |
    sum(rate(http_requests_total{status="502"}[1m])) /
      sum(rate(http_requests_total[1m])) * 100 > 5
  for: 5m
  labels:
    severity: error
  annotations:
    summary: "HTTP errors 502 (instance {{ $labels.instance }})"
    description: |
      "Too many HTTP requests with status 502 (> 5%)\n  VALUE = {{ $value }}\n
      LABELS: {{ $labels }}"

```

```go 11[29:37] title="Pitfall #4: Naming - Stability" subtitle="Let's say we are renaming metric..."

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_protocol_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

alert: HttpToMany502Errors
  expr: |
    sum(rate(http_requests_total{status="502"}[1m])) /
      sum(rate(http_requests_total[1m])) * 100 > 5
  for: 5m
  labels:
    severity: error
  annotations:
    summary: "HTTP errors 502 (instance {{ $labels.instance }})"
    description: |
      "Too many HTTP requests with status 502 (> 5%)\n  VALUE = {{ $value }}\n
      LABELS: {{ $labels }}"

```

```go title="Pitfall #4: Naming - Stability" subtitle="Ooops..."

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_protocol_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

## BOOM!💥 This alert will never fire but also will not fail!
## Rename can cause issues like this in Alerts, Recording rules, Dashboards and more..
alert: HttpToMany502Errors
  expr: |
    sum(rate(http_requests_total{status="502"}[1m])) /
      sum(rate(http_requests_total[1m])) * 100 > 5
  for: 5m
  labels:
    severity: error
  annotations:
    summary: "HTTP errors 502 (instance {{ $labels.instance }})"
    description: |
      "Too many HTTP requests with status 502 (> 5%)\n  VALUE = {{ $value }}\n
      LABELS: {{ $labels }}"

```

</CodeSurfer>

---
import harry_potter from './static/harry_potter.gif'

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #5: Cardinality - Unbounded labels</h2>

<img src={harry_potter} style="height: 50%; width: 80%; margin-top: 5%"/>

<Notes>

KEMAL

When we talk about Prometheus it always comes down to cardinality.

What is cardinality actually? So the cardinality, in Prometheus context, is the amount of unique time-series you have in your system.

And don't forget each label value that you add to your metric creates another time-series.

So for example, if you have a label containing HTTP methods would have a cardinality of 2 if you had only GET and POST in your application.

Labels what make Prometheus stong. However you should always watch out how you use them.

Things could get out of control pretty quickly.

Let's see an example.

</Notes>

---

<Notes>

KEMAL

Everything looks good, let's run our loadbalancer and get our metrics.

1)
Let's define a metric called `conntrackdialer_conn_failed_total`, to track the number of failed connections we have in our loadbalancer.
And let's have a label called `reason` to track failure reasons.

2)
Let's use our metric in action and increment our metric with corresponding error.

3)
Let's check out our metrics...

That is not what we expected.
What went wrong?

We shoudn't use arbitrary data as label values.
Always keep track of things that you put in your labels.

So let's see how we can fix it.

</Notes>

---

<CodeSurfer>

```go title="Pitfall #5: Cardinality - Unbounded labels" subtitle="Let's define a metric."

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

```

```go title="Pitfall #5: Cardinality - Unbounded labels" subtitle="Let's define a metric." 5:9

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

```

```go title="#5: Cardinality - Unbounded labels"  subtitle="Let's track request per path"

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method", "path"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

```

```go title="#5: Cardinality - Unbounded labels" subtitle="Let's check out our metrics... 😲"

# HELP http_requests_total Tracks the number of HTTP requests.
# TYPE http_requests_total counter
http_requests_total{code="200", method="", path="/metrics"} 15
http_requests_total{code="200", method="", path="/status"} 2
http_requests_total{code="200", method="", path="/stores"} 13
http_requests_total{code="200", method="", path="/ping"} 123
http_requests_total{code="200", method="", path="/articles"} 221
http_requests_total{code="200", method="", path="/article/1"} 1
http_requests_total{code="200", method="", path="/article/2"} 14
http_requests_total{code="200", method="", path="/article/3"} 10
http_requests_total{code="200", method="", path="/article/4"} 1

```

```go title="#5: Cardinality - Unbounded labels" subtitle="Just noise 😲"

# HELP http_requests_total Tracks the number of HTTP requests.
# TYPE http_requests_total counter
http_requests_total{code="200", method="", path="/metrics"} 15
http_requests_total{code="200", method="", path="/status"} 2
http_requests_total{code="200", method="", path="/stores"} 13
http_requests_total{code="200", method="", path="/ping"} 123
http_requests_total{code="200", method="", path="/articles"} 221
http_requests_total{code="200", method="", path="/article/1"} 1
http_requests_total{code="200", method="", path="/article/2"} 14
http_requests_total{code="200", method="", path="/article/3"} 10
http_requests_total{code="200", method="", path="/article/4"} 1
http_requests_total{code="401", method="", path="/articles"} 221
http_requests_total{code="401", method="", path="/article/1"} 1
http_requests_total{code="401", method="", path="/article/2"} 14
http_requests_total{code="401", method="", path="/article/3"} 10
http_requests_total{code="401", method="", path="/article/4"} 1
http_requests_total{code="403", method="", path="admin"} 287
http_requests_total{code="404", method="", path="/robots.txt"} 11424
http_requests_total{code="404", method="", path="/lookup/zzx"} 12
http_requests_total{code="404", method="", path="/helloissomeonethre"} 1
http_requests_total{code="401", method="", path="/article/112"} 6
http_requests_total{code="401", method="", path="/article/222"} 48
http_requests_total{code="401", method="", path="/article/hello"} 10
http_requests_total{code="401", method="", path="/article/99"} 1

```

</CodeSurfer>

---

<CodeSurfer>

```go title="#5: Cardinality - Unbounded labels"  subtitle="A better option."

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method", "path"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

```

```go title="#5: Cardinality - Unbounded labels"  subtitle="A better option."

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method", "handler"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

```

```go title="#5: Cardinality - Unbounded labels"  subtitle="A better option."

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method", "handler"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

// TODO: Add mux.Handle ...

```

</CodeSurfer>

<Notes>

KEMAL

TODO: Prometheus and metrics in general not for logging and discrete event tracking

1)
Here we are at the beginning again, so how can we improve this?

2)
One of the tactics that I use is to define labels as constants.

3)
And then create a helper function to map arbitrary errors to constant labels.

Same principle is valid for the paths, user ids, session ids.
Anything you can think of as arbitrary.

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #6: Cardinality - Histogram Explosion</h2>

<Notes>

KEMAL

Histograms are more complex metric types compare to metrics and gauges.

Not only underneath, a single histogram includes a couple of counters with labels, it is also more difficult to use it correctly.

They do sampled observations, typically on request durations or response sizes.

They track the number of observations and the sum of the observed values, allowing you to calculate the average of the observed values.

What's the problem with cardinality?

As I told underneath by default they have a couple of labeled counters.

By default they expose, 12-14 counters.

So anything you add, builds up.

Let's see an example.

</Notes>

---

<Notes>

KEMAL

1)
Again let's start with defining our good old http request duration metric with a default set of labels.

2)
Let's get our metrics.
They look good.
Let's say we run our loadbalancer for a while and we realize that requests take longer than we anticipated.

3)
So let's add some more metrics.
It's fine just a couple of more time series per histogram.

4)
Let's get our metrics again.
Same sceneraio, we need more buckets let's add some more.

5)
we are good for now, let's leave it be.

</Notes>

<CodeSurfer>

```go title="Pitfall #6: Histogram Cardinality Explosion"

var (
	buckets = []float64{0.001, 0.01, 0.1, 0.3, 0.6, 1, 3}
)

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
				Buckets: buckets,
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```go title="Pitfall #6: Histogram Cardinality Explosion"

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.001"} 0
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.01"} 1
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.1"} 3
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.3"} 6
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.6"} 6
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="1"} 6
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="3"} 8
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="+Inf"} 302
http_request_duration_seconds_sum{code="200",handler="/lb",method="get"} 3230.08239999999999999
http_request_duration_seconds_count{code="200",handler="/lb",method="get"} 302

```

```go title="Pitfall #6: Histogram Cardinality Explosion" 3,17

var (
	buckets = []float64{0.001, 0.01, 0.1, 0.3, 0.6, 1, 3, 6, 9, 20, 30, 60, 90, 120}
)

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
				Buckets: buckets,
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```go title="Pitfall #6: Histogram Cardinality Explosion"

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.001"} 0
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.01"} 1
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.1"} 3
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.3"} 6
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.6"} 6
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="1"} 6
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="3"} 8
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="6"} 30
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="9"} 33
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="20"} 38
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="30"} 39
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="60"} 41
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="90"} 45
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="120"} 47
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="+Inf"} 302
http_request_duration_seconds_sum{code="200",handler="/lb",method="get"} 3230.08239999999999999
http_request_duration_seconds_count{code="200",handler="/lb",method="get"} 302

```

```go title="Pitfall #6: Histogram Cardinality Explosion" 3

var (
	buckets = []float64{0.001, 0.01, 0.1, 0.3, 0.6, 1, 3, 6, 9, 20, 30, 40, 50, 60, 90, 120, 150, 200}
)

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
				Buckets: buckets,
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```go title="Pitfall #6: Histogram Cardinality Explosion"

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.001"} 0
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.01"} 1
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.1"} 3
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.3"} 6
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.6"} 6
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="1"} 6
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="3"} 8
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="6"} 30
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="9"} 33
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="20"} 38
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="30"} 39
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="60"} 41
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="90"} 45
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="120"} 47
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="150"} 118
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="200"} 258
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="+Inf"} 302
http_request_duration_seconds_sum{code="200",handler="/lb",method="get"} 3230.08239999999999999
http_request_duration_seconds_count{code="200",handler="/lb",method="get"} 302

```

</CodeSurfer>

---

import itisfine from './static/itisfine.jpg'

<img src={itisfine} style="height: 75%; margin-top: 3%"/>

---

<CodeSurfer>

```go title="Pitfall #6: Histogram Cardinality Explosion"

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="0.001"} 0
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="0.01"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="0.1"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="0.3"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="0.6"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="1"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="3"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="6"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="9"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="20"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="30"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="40"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="50"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="60"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="90"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="120"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="150"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="200"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="+Inf"} 2
http_request_duration_seconds_sum{code="200",handler="/lb",method="post"} 0.0026940999999999996
http_request_duration_seconds_count{code="200",handler="/lb",method="post"} 2
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.001"} 0
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.01"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.1"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.3"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.6"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="1"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="3"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="6"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="9"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="20"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="30"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="40"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="50"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="60"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="90"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="120"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="150"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="200"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="+Inf"} 146
http_request_duration_seconds_sum{code="200",handler="/metrics",method="get"} 0.3082099000000001
http_request_duration_seconds_count{code="200",handler="/metrics",method="get"} 146
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="0.001"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="0.01"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="0.1"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="0.3"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="0.6"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="1"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="3"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="6"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="9"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="20"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="30"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="40"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="50"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="60"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="90"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="120"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="150"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="200"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="+Inf"} 1
http_request_duration_seconds_sum{code="200",handler="demo-500-sometimes",method="post"} 4.01e-05
http_request_duration_seconds_count{code="200",handler="demo-500-sometimes",method="post"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="0.001"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="0.01"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="0.1"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="0.3"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="0.6"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="1"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="3"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="6"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="9"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="20"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="30"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="40"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="50"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="60"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="90"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="120"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="150"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="200"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="+Inf"} 1
http_request_duration_seconds_sum{code="200",handler="demo-refused-conn-sometimes",method="post"} 4.46e-05
http_request_duration_seconds_count{code="200",handler="demo-refused-conn-sometimes",method="post"} 1


```

</CodeSurfer>

<Notes>
	KEMAL

	With histograms, cardinality multiplies very quickly!

	Be very considered with your histograms.

	Choose what you put in those labels wisely.

	And do not just choose your histogram buckets randomly.

	Which is actually my next point.
</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #7: Poorly Chosen Histogram Buckets</h2>

<Notes>

KEMAL

Histograms are actually great to collect observations from your system.

Histograms can be used to produce arbitrary quantile estimations. You can even estimate the mean.

They accummulate their observation in to buckets.

Hence they have significantly less storage requirements compare to storing raw data.

As a result performance of your histogram tightly depends on your bucket layout.

Lets see some example bucket layouts and how to fix them.

</Notes>

---

<Notes>

TODO: SLOSs
TODO: Why we need to adjust the buckets on the client side?
TODO: What are the addvantages?

KEMAL

1)

So what's wrong here.

Prometheus implements histograms as cumulative histograms.
This means the first bucket is a counter of observations less than or equal to 0.5, the second bucket is a counter of observations less than or equal to 1, etc.
Each bucket contains the counts of all prior buckets.

2)
Let's fix it.

So coming up for a good bucket layout is hard.

Knowing Your Distribution.

Accuracy is controlled by the granularity of your bucket layout.
And adding more bucket increases cardinality by magnitudes.

My suggestion define your service level objectives and create your buckets accordingly.

</Notes>

<CodeSurfer>

```go title="Pitfall #7: Poorly chosen Histogram buckets"

var (
	buckets = []float64{0.001, 0.01, 0.1, 0.3, 0.6, 1, 3}
)

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
				Buckets: buckets,
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```go title="Pitfall #7: Poorly chosen Histogram buckets" 3

var (
	buckets = []float64{0.001, 0.01, 0.1, 0.3, 0.6, 1, 3}
)

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
				Buckets: buckets,
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```go

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.001"} 1
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.01"} 49
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.1"} 49
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.3"} 49
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.6"} 49
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="1"} 49
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="3"} 49
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="+Inf"} 49
http_request_duration_seconds_sum{code="200",handler="/lb",method="get"} 0.11527970000000001
http_request_duration_seconds_count{code="200",handler="/lb",method="get"} 49

```

```go title="Pitfall #7: Poorly chosen Histogram buckets" subtitle="Know your distribution." 3:5

var (
	// prometheus client libraries are your friends!
	buckets = prometheus.LinearBuckets(0.001, 0.0002, 6)
	// buckets = prometheus.LinearBuckets(0.001, 2, 6)
)

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
				Buckets: buckets,
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```go

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.001"} 3
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.0012000000000000001"} 3
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.0014000000000000002"} 10
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.0016000000000000003"} 21
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.0018000000000000004"} 25
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="0.0020000000000000005"} 29
http_request_duration_seconds_bucket{code="200",handler="/lb",method="get",le="+Inf"} 49
http_request_duration_seconds_sum{code="200",handler="/lb",method="get"} 0.10939249999999999
http_request_duration_seconds_count{code="200",handler="/lb",method="get"} 49

```

</CodeSurfer>

---

### Summary

<Notes>

1)
Observe your applications, monitoring is not optional.
You have to know what's going on with your application on production.
Determin your service level objectives.
Build alerts on them.
Build dashboards on them.

2)
Now, since you have also alerts and dashboads in place. You rely on them.
Test them as you test your business logic.

3)
Last but not the least,

So avoid global state, make your life easy for yourself.

"magic is bad; global state is magic" by Peter Bourgon

</Notes>

<Appear>
	<h2>Monitoring is essential.</h2>
	<h2>Unit Test Your Instrumentation.</h2>
	<h2>Avoid Global Registry.</h2>
</Appear>

---

import ss_repo from './static/ss_repo.png'

##### [https://github.com/observatorium/observable-demo](https://github.com/observatorium/observable-demo)

<Image src={ss_repo} size='contain' />

<Notes>

KEMAL

If you want to learn more, try it yourself or dig deeper in the code, here is a link to our loadbalancer repo.

</Notes>

---

# Thank you!

import red_hat_white from './static/red_hat_white.png'

<img src={red_hat_white} style="height: 20%"/>

<div style="font-size: 70%">

##### [https://github.com/kakkoyun/are-you-testing-your-observability](https://github.com/kakkoyun/are-you-testing-your-observability)

</div>

<Notes>

So that's from us.
Thank you very much for listening.

And you can also find the slides in that links.

</Notes>

---

# References:

<div style="font-size: 90%">

* [Prometheus](https://prometheus.io)
* [Prometheus - client_go](https://godoc.org/github.com/prometheus/client_golang/prometheus)
* [Thanos](https://thanos.io)
* [Why globals are magic](https://peter.bourgon.org/blog/2017/06/09/theory-of-modern-go.html)
* [Red Method](https://grafana.com/blog/2018/08/02/the-red-method-how-to-instrument-your-services)
* [Prometheus - Histogram](https://prometheus.io/docs/practices/histograms/)
* [Prometheus Histograms – Past, Present, and Future](https://www.youtube.com/watch?v=7sQFkaMCyEI)
* [Roboust Perception Blog](https://www.robustperception.io/blog)

</div>

