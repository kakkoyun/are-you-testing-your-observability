import './styles.css'

import { Head, Image, Appear, Notes, Invert, Split } from "mdx-deck"

import { CodeSurfer, CodeSurferColumns, Step } from "code-surfer"
import { shadesOfPurple } from "@code-surfer/themes"

import thanos from './static/thanos_logo.svg'
import prometheus from './static/prometheus_logo.svg'
import redhat from './static/red_hat_logo.png'

import ss_tsdb_01 from './static/ss_tsdb_01.png'

export const theme = shadesOfPurple;

<Head>
	<title>Are you testing your Observability?</title>
</Head>

<CodeSurfer>

```go 6[17:53],7[17:53],11[17:53]
package main

import "fmt"

func main() {
	fmt.Println("Are you testing your Observability?")
	fmt.Println("      --- Metrics Edition ---      ")



	fmt.Println("    GoDays 22.01.2020, Berlin      ")
}
```

</CodeSurfer>

<Notes>

Hello everyone!

We are extremely excited to be here in GoDays conference, and be able to speak about topics we both love:

* observability
* programming in go

At the end of this talk we would like you to know:

* why instrumenting Go applications with actionable metrics is essential
* how to do it quickly and smoothly in Go, how to test it
* last but not the least: what are the common mistakes you should avoid, mistakes that
we seen a lot during our work with Go and metrics in WILD open source WORLD.

But before that: Short introduction!

</Notes>

---

<div style="width: 100%; height: 50%; overflow: auto;">
<img src="https://storage.googleapis.com/gopherizeme.appspot.com/gophers/1a34872cf0ec375b9fc44ce654fc03a5abc42dc4.png" style="height: 90%; float: left;"/>

#### Bartek Plotka

<div style="font-size: 80%">
Principal Software Engineer @ Red Hat<br/>
OpenShift Monitoring Team<br/>
Prometheus and Thanos Maintainer<br/><br/>

<img src="https://raw.githubusercontent.com/kakkoyun/are-you-testing-your-observability/master/static/twitter.png" style="height: 40px; width: 40px;"/> <img src="https://raw.githubusercontent.com/kakkoyun/are-you-testing-your-observability/master/static/github.png" style="height: 40px; width: 40px;"/> @bwplotka
</div>
</div>

<div style="width: 100%; height: 50%; overflow: auto;">
<img src="https://storage.googleapis.com/gopherizeme.appspot.com/gophers/9806438d5acfb3a108eeaab302de0e32f8a489ad.png" style="height: 90%; float: left;"/>

#### Kemal Akkoyun

<div style="font-size: 80%">
Software Engineer @ Red Hat<br/>
OpenShift Monitoring Team<br/>
Thanos Contributor<br/><br/>

<img src="https://raw.githubusercontent.com/kakkoyun/are-you-testing-your-observability/master/static/twitter.png" style="height:40px; width: 40px;"/> @kkakkoyun <span/>
<img src="https://raw.githubusercontent.com/kakkoyun/are-you-testing-your-observability/master/static/github.png" style="height: 40px; width: 40px;"/> @kakkoyun
</div>
</div>

<Notes>

My name is Bartek Plotka, I am an engineer working at Red Hat in the Monitoring team, I love open source and Go.
I am in Prometheus team and I am a co-author of Thanos project, which is a durable system for scaling Prometheus.

With me there is Kemal: Kemal TODO intro

</Notes>

---

<div style="width: 100%; height: 50%; overflow: auto;">
<img src={prometheus} style="height: 50%; margin: auto; display: block; margin-top: 100px;" />
</div>

<div style="width: 100%; height: 50%; overflow: auto;">
<img src={thanos} style="height: 50%; margin: auto; display: block; margin-top: 100px;" />
</div>

<Notes>

We are both working in the same monitoring team for Red Hat.
We are building scalable Observability solutions and platforms for OpenShift.
But also as one of the major part of our work is maintaining Prometheus and Thanos projects on a daily basis.

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;"> Let's implement an HTTP L7 loadbalancer in Go! ❤ </h2>

️*Because why not?*

<Appear>
   <img src="https://docs.google.com/drawings/d/e/2PACX-1vQKHs_qMJWPKulEUxoDcLXww4Kq32IcJfPLbnnBfUDMj3AxQzuhRJtCKbw-i6TgqhBoRCfWo7RnV1nm/pub?w=960&h=720"/>
</Appear>

<Notes>

So let's do something fun! Let's implement application level HTTP loadbalancer in Go? Why?
Well these days with replicated microservices loadbalancer are crucial. HTTP is the most popular
protocol this days for API communication, and application level loadbalancing gives us more control
in terms of things like request based load balancing instead of connection based, graceful shutdowns,
inspection and distribution of load.

Appear:

So let's say we implemented transparent loadbalancer as presented in this diagram. From high level design we have:

* single HTTP server that implements ServerHTTP method, so handler via awesome ReverseProxy in standard httputil package.
* ReverseProxy allows us to implement custom Transport, so RoundTripper interface which is to send
some request to remote backend.
* our load balancing RoundTipper implementation called lbtranport is internally using then few components:

  * Discoverer which gives us targets to proxy / loadbalance request to
  * RoundRobinPicker which chooses right target to proxy user request to in round robin manner, so: replica 1, 2,3, then again 1, 2, 3
  * And at the end it uses HTTP transport so, http.RoundTripper that belongs to picked target and proxy request through and proxy response back to the user.

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Wait... Anything missing?</h2>

<img src="https://docs.google.com/drawings/d/e/2PACX-1vQKHs_qMJWPKulEUxoDcLXww4Kq32IcJfPLbnnBfUDMj3AxQzuhRJtCKbw-i6TgqhBoRCfWo7RnV1nm/pub?w=960&h=720"/>

<Notes>

This is great, it looks like this implementation should work.. but are we sure it's production ready?

So let's say we deploy couple of replicas of our loadbalancer on production in front of some microservice and let
it run for longer time.

As soon as it starts running, we hit /lb endpoint manually and we can it works. So we are good, right?

Well...

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Wait... Anything missing?</h2>

<img src="https://docs.google.com/drawings/d/e/2PACX-1vT4N2dSOi0FhqFx1yVeNYPlJk6kT8o-7FdgvXvwpXiWVkK9MKM4SLflq4o3rJni9hEjWjrs7HKg0iOr/pub?w=960&h=720"/>

<Notes>

     Does it actually work for 100% users or only me?
     I have better things to do then manually hitting /lb endpoint to check if it works constantly, right?
     Are all request fast enough?

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Wait... Anything missing?</h2>

<img src="https://docs.google.com/drawings/d/e/2PACX-1vTOKGrz6rfXVoHSfdNY4Pe901pdaJizjylwqyhkwMU53bRy9VXAJE4hTfGJrGiDncfg3Coh7Par67lu/pub?w=960&h=720"/>

<Notes>

    Is discovery really working? How many replicas it discovers, e.g through DNS?

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Wait... Anything missing?</h2>

<img src="https://docs.google.com/drawings/d/e/2PACX-1vR-mA1zdYoQ-6pPjcSZFGTNIH1RV_3_VymMYOW1Y_OblYxiNoW-R-PBIVGHjNTHeyqiA-H9GIcZnQ6p/pub?w=960&h=720"/>

<Notes>

    Is round robin picker, picking in round robin matter?
    Is 1/3 of all requests actually going to replica 1? What's the distribution?
    Why one backend is overloaded with request?

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Wait... Anything missing?</h2>

<img src="https://docs.google.com/drawings/d/e/2PACX-1vTxiQx99iCG7WgA2sfceWofNnol0ynukyDZ3iCoOY02CDcyvkHIJC4J4SQvSYMYAbiDjbhs_3WWsGCr/pub?w=960&h=720"/>

<Notes>

   Users reports that endpoint is slow, is it backend or latency of target of latency of loadbalancing?

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Wait... Anything missing?</h2>

<img src="https://docs.google.com/drawings/d/e/2PACX-1vRz638FUDhV2SGsC5bco5wVnE0VHb_OLU6g4SaOL108D1KZLXkzmTgSHz6d-d-OPYkij2BzA27FVio2/pub?w=960&h=720"/>

<Notes>

  One of the nodes that loadbalancer running on OOM-ed, how much resources loadbalancer even use? Do we have a leak?

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Wait... Anything missing?</h2>

<img src="https://docs.google.com/drawings/d/e/2PACX-1vTTmGW2ky_qxu9TEYUsnvQwHBe0lhTSc07UHHSCRsjHldVwm2fR2GpIEHZkZD5HbW3hObU4TXJnN7N4/pub?w=960&h=720"/>

<Notes>

  What version of binary we were running 2 days ago at 2pm? Something was wrong back then.

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;"> We need: Observability!</h2>

<img src="https://docs.google.com/drawings/d/e/2PACX-1vSvJ_htd2Q-qEzCkxjl057HEiGpnP97JLSdHVtjqlH4_huRIp8kgmhD0vRbufTCF4UWjkuje-l2Lli8/pub?w=960&h=720"/>

<Notes>

  As you can see there are plenty of questions that would be not answered when running service like this on
  production, without proper monitoring. That's why in SRE book you will find monitorin as the foundation
  of any system, BEFORE even the system itself!

  As you are familiar the some monitoring signals we can introduce are: traces, logs and metrics.
  Guess what Which of those will give us answer to our questions like distribution of requests or histogram of tail latency?

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;"> Let's instrument our loadbalancer with Prometheus metrics!</h2>
<br/>
<br/>

<ul>
<Appear>
<li>Cheap</li>
<li>Near Real Time</li>
<li>Actionable (Alert-able)</li>
<div>
    <img src={prometheus} style="height: 50%; margin: auto; display: block; margin-top: 100px;" />
    <p>http://prometheus.io</p>

</div>
</Appear>
</ul>

<Notes>

	Metrics, yup!

	Metrics most likely give us the answers to our questions.
	Answer that is in comparison to logs and traces:

	* CHEAPer to calculate
	* Near Real Time
    * Clear and Actionable, so you can alert on those.

    In practice metrics should be the first item on monitoring list that you should do if you care to run
    your service reliably.

    Appear:

    Why Prometheus though? Well I might be bias but Prometheus is currently one of the simplest and
    cheapest option for collecting, storing and querying metrics as well as reliable alerting.
    It is part of CNCF, fits for small solution as well as for bigger ones with help of cloud native projects like Thanos, Cortex, m3db and others

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;"> Let's instrument our loadbalancer with Prometheus metrics!</h2>

<img src="https://docs.google.com/drawings/d/e/2PACX-1vT4N2dSOi0FhqFx1yVeNYPlJk6kT8o-7FdgvXvwpXiWVkK9MKM4SLflq4o3rJni9hEjWjrs7HKg0iOr/pub?w=960&h=720"/>

<Notes>

So.. how to add Prometheus metrics to our loadbalancer? Let's say we want to answer for how many
users our loadbalancer is working?

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;"> Let's instrument our loadbalancer with Prometheus metrics!</h2>

<img src="https://docs.google.com/drawings/d/e/2PACX-1vREgXi-KbyUIdbSbaFsIQbkWE7ZrcPA0cBya53PB-jfIRL1E6uMvJC4HUc4Ca9Rujizv_-zQhEr3P_O/pub?w=960&h=720"/>

<Notes>

So.. how to add Prometheus metrics to our loadbalancer? We can do that by incrementing certain http_requests_total counter
whenever a loadbalancing request occur, reporting method that was used, and HTTP status code that was returned.

We can do that in few simple steps.

</Notes>

---

<CodeSurfer>

```go title="Server HTTP request counter"

import "github.com/prometheus/client_golang/prometheus"

```

```go 5,6,7,8,9,10 title="Server HTTP request counter"

import "github.com/prometheus/client_golang/prometheus"

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

```

```go 13,14,18,19 title="Server HTTP request counter"

import "github.com/prometheus/client_golang/prometheus"

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

// Top level ServerHTTP handler.
func ServerHTTP(w http.ResponseWriter, r *http.Request) {
  statusRec := newStatusRecorder(w)
  next.ServeHTTP(statusRec, r)

  // Increment our counter with written status code and request method.
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)
}

```

```go 23 title="Server HTTP request counter"

import "github.com/prometheus/client_golang/prometheus"

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

// Top level ServerHTTP handler.
func ServerHTTP(w http.ResponseWriter, r *http.Request) {
  statusRec := newStatusRecorder(w)
  next.ServeHTTP(statusRec, r)

  // Increment our counter with written status code and request method.
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)
}

func init() {
	prometheus.MustRegister(serverRequestsTotal)
}

```

</CodeSurfer>

<Notes>

1) During our talk We will be talking mainly about Prometheus client Go module, which is designed to help
with instrumenting any Go application. It's tiny, heavily optimized and quite simple.
So first, what we need to do is to import it.

2) As a next step we need to define variable for the our counter of requests. We pick a name, a description
and certain "labels" which will be our dimensions of this counter. Each unique value in any of those labels will
result in totally new series in Prometheus system.

3) Next step is to actually count our requests. Let's create a simple wrapper of http server which will increment
the counter with the status code that the server returned and requested method.

4) Something that is easy to forget it another step. The counter has to be registered somewhere in order
to be exposed for Prometheus. Let's do this once in `init` function and register it in GLOBAL
Prometheus registry.

</Notes>

---

<CodeSurferColumns>

<Step title="Server HTTP request counter" subtitle="Why we need to register?">

```go 3

func init() {
	prometheus.MustRegister(serverRequestsTotal)
}

```

<img src="https://docs.google.com/drawings/d/e/2PACX-1vREgXi-KbyUIdbSbaFsIQbkWE7ZrcPA0cBya53PB-jfIRL1E6uMvJC4HUc4Ca9Rujizv_-zQhEr3P_O/pub?w=960&h=720"/>

</Step>
<Step title="Server HTTP request counter" subtitle="Registry is used by Prometheus /metrics handler">

```go 7,12

func init() {
	prometheus.MustRegister(serverRequestsTotal)
}

mux := http.NewServeMux()
mux.Handle("/metrics", promhttp.Handler())
mux.Handle("/lb", ...)

// Other handlers...

srv := &http.Server{Handler: mux}

// Run server...

```

<img src="https://docs.google.com/drawings/d/e/2PACX-1vRcDyIrN_3tzI_QbA99QkvMHAHDIZZi-sh1stXoul_M-zyM1GQPdOCvC_h8nU91l-uQ-UUKjhuGhlYj/pub?w=960&h=720"/>

</Step>
</CodeSurferColumns>

<Notes>

1) So what we accomplished by registering this metric. That's a good question.
We need last step which is:

2) HTTP handler for metric page, which serves simple text page with all metrics.
Once we add that our loadbalancer is correctly exposing our http_requests_total to the outside world.

</Notes>

---

import graph_requests from './static/graph-requests.png'

<CodeSurfer>

```go 4,6 title="From code to graph" subtitle="We defined & instrumented our metric"
var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

```

```go 4,6,10,13,14 title="From code to graph" subtitle="It is now exposed under /metrics"
var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

// Part of response from /metrics HTTP endpoint.
# HELP http_requests_total Tracks the number of HTTP requests.
# TYPE http_requests_total counter
http_requests_total{code="200", method="get"} 1089
http_requests_total{code="500", method="get"} 46
```

</CodeSurfer>
<Notes>

1) So let's talk how we can use our metric in Prometheus. As you remember we defined and we increment it every HTTP request.
2) Loadbalancer now serves /metrics page which exposes our metrics in Prometheus supported text format. As you can see
each code and method are a seperate counter, we mostly have successes.

</Notes>

---

<h2 style="text-align: center; margin: 0px 10px 0 10px;">Prometheus can now collect metrics from our Loadbalancer</h2>

*Pulling e.g every 15 seconds*

<img src="https://docs.google.com/drawings/d/e/2PACX-1vQazezdwEI7-_Naf_aMSGipdrSNMoDgc9YtrFyO_ttl1kuyeI7jn8lFtfVk8jQ35BQEAg2m8CvYGp3r/pub?w=590&h=701"/>

<Notes>

3) We now can use running binary of Prometheus and point to the loadbalancer /metrics page. Prometheus then will
visit this page which is called scrape every given interval and collect all exposed metrics.

</Notes>

---

<h2 style="text-align: center; margin: 0px 10px 0 10px;">Graph: Prometheus UI</h2>

<img src={graph_requests} style="height: 70%; margin-top: 5%"/>

<Notes>

With that we can after some time, visit Prometheus UI where we can produce graphs. For example we can query
the number of requests per minute by code and method. We can see that per minute we have 120 requests in total,
with some small portion of those being error responses.

</Notes>

---

import pitfalls from './static/pitfall.gif'
import golang from './static/go.png'

<div>
    <h1 style="text-align: center; margin: 0px 10px 0 10px;">
        <img src={golang} style="width: 7%; margin-top: 5%"/>
        &nbsp;+&nbsp;
        <img src={prometheus} style="width: 10%; margin-top: 5%"/>
        &nbsp;&nbsp;Pitfalls
    </h1>
</div>

<img src={pitfalls} style="height: 50%; margin-top: 5%"/>

<Notes>
    So it looked easy right? And it is easy in most cases. However during this talk we would like
    to present what we learnt during few year, while developing and reviewing instrumentation Go code that
    is meant to be run on production, mainly in open source.

    Together with Kemal wil go though few less or more advanced issues we seen and how to resolve them.
    And we will be very honest with you. We are egoists. And we talk about this so when anyone in open or close seource
    develop a Go modules we reuse or project we will use someday, will avoid those issues. (:
</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #1: Global Registry</h2>
<br/>
<br/>
<h6 style="text-align: center; margin: 0 10px 0 10px;">"magic is bad; global state is magic" by Peter Bourgon</h6>

<Notes>
    First one! Globals.

    There was a saying in Peter Bourgon blog post "A theory of Modern Go"

    This is very true in case of Prometheus client, especially if you are instrumenting some Go package with metrics
    that your project, or maybe anyone in open source is using.

    So let's focus on what can go wrong when using Globals when instrumenting our loadbalancer with metrics.

    Ref: https://peter.bourgon.org/blog/2017/06/09/theory-of-modern-go.html

</Notes>

---

<CodeSurfer>

```go title="Pitfall #1: Global Registry" subtitle="We have 2 global variables here."

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

func init() {
	prometheus.MustRegister(serverRequestsTotal)
}

  // ...
  // Increment our counter with written status code and request method.
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```diff 3,4,5,6,7,8 title="Pitfall #1: Global Registry" subtitle="Package-level metric variable."
```

```go 12[16:80] title="Pitfall #1: Global Registry" subtitle="and global DefaultRegisterer."

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

func init() {
	prometheus.DefaultRegisterer.MustRegister(serverRequestsTotal)
}

  // ...
  // Increment our counter with written status code and request method.
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go 15,16,17,18,19,20,21,22 title="Pitfall #1: Globals: No flexibility" subtitle="What if I have more handlers than one?"

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

func init() {
	prometheus.DefaultRegisterer.MustRegister(serverRequestsTotal)
}

  // For endpoint /one:
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /two:
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /three:
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go title="Pitfall #1: Globals: No flexibility" subtitle="Nice, but for what handler?"

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

func init() {
	prometheus.DefaultRegisterer.MustRegister(serverRequestsTotal)
}

  // For endpoint /one:
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /two:
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /three:
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  # HELP http_requests_total Tracks the number of HTTP requests.
  # TYPE http_requests_total counter
  http_requests_total{code="200", method="get"} 2445
  http_requests_total{code="500", method="get"} 53

```

```go title="Pitfall #1: Getting rid of globals."

var (
	serverRequestsTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Tracks the number of HTTP requests.",
		}, []string{"code", "method"},
	)
)

func init() {
	prometheus.DefaultRegisterer.MustRegister(serverRequestsTotal)
}

  // For endpoint /one:
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /two:
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /three:
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go title="Pitfall #1: Getting rid of globals." subtitle="Introduce instance of metrics!"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics() *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	return m
}

func init() {
	prometheus.DefaultRegisterer.MustRegister(serverRequestsTotal)
}

  // For endpoint /one:
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /two:
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /three:
  serverRequestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go title="Pitfall #1: Getting rid of globals." subtitle="Create new instance of it"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics() *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	return m
}

  metrics := NewServerMetrics()

func init() {
	prometheus.DefaultRegisterer.MustRegister(metrics.requestsTotal)
}

  // For endpoint /one:
  metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /two:
  metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /three:
  metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go title="Pitfall #1: Getting rid of globals." subtitle="Register using Custom Registerer (composition!)"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

  metrics := NewServerMetrics(reg)

  // For endpoint /one:
  metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /two:
  metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /three:
  metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

``` go title="Pitfall #1: Getting rid of globals." subtitle="Now it's package-level user friendly!"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

  metrics1 := NewServerMetrics(
    prometheus.WrapWithLabels(prometheus.Labels{"handler":"/one"}, reg),
  )
  metrics2 := NewServerMetrics(
    prometheus.WrapWithLabels(prometheus.Labels{"handler":"/two"}, reg),
  )
  metrics3 := NewServerMetrics(
    prometheus.WrapWithLabels(prometheus.Labels{"handler":"/three"}, reg),
  )

  // For endpoint /one:
  metrics1.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /two:
  metrics2.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /three:
  metrics3.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

```

```go title="Pitfall #1: Getting rid of globals." subtitle="We can have request counter per handler (:"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

  metrics1 := NewServerMetrics(
    prometheus.WrapWithLabels(prometheus.Labels{"handler":"/one"}, reg),
  )
  metrics2 := NewServerMetrics(
    prometheus.WrapWithLabels(prometheus.Labels{"handler":"/two"}, reg),
  )
  metrics3 := NewServerMetrics(
    prometheus.WrapWithLabels(prometheus.Labels{"handler":"/three"}, reg),
  )

  // For endpoint /one:
  metrics1.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /two:
  metrics2.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  // For endpoint /three:
  metrics3.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)

  # HELP http_requests_total Tracks the number of HTTP requests.
  # TYPE http_requests_total counter
  http_requests_total{handler="/one", code="200", method="get"} 1445
  http_requests_total{handler="/one", code="500", method="get"} 23
  http_requests_total{handler="/two", code="200", method="get"} 445
  http_requests_total{handler="/two", code="500", method="get"} 0
  http_requests_total{handler="/three", code="200", method="get"} 645
  http_requests_total{handler="/three", code="500", method="get"} 40

```

</CodeSurfer>

<Notes>

1) Let's take our example or http requests_total metric. We have 2 global states here.

2) As you can see metric is a global, package level variable. When we register it we do it once per package import as well.

3) Second place of global state is Must register. What is hidden under prometheus.MustRegister is actually a Global
Registerer.

Now what's the issue here? Why is that problematic?

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #2: Lack of Consistency</h2>
<br/>
<br/>
<Appear>

<h5 style="text-align: center; margin: 0 10px 0 10px;">The Four Golden Signals, USE method, RED method etc...</h5>

<div>
<br/>
<br/>
<ul>
<li><span style="color: red">R</span>: Requests per second (saturation).</li>
<li><span style="color: red">E</span>: Errors per second.</li>
<li><span style="color: red">D</span>: Duration (tail latency).</li>
</ul>
</div>
</Appear>

<Notes>

Why

1) This helps to be sure you have main signals upfront of potential debugging or alerting needs.
2) It helps to reuse common "RED method type" alerts, recording rules and dashboards. e.g mixin project.

</Notes>

---

<CodeSurfer>

```go title="Pitfall #2: Lack of consistency" subtitle="Does this satisfy RED method?"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

```

```diff 11,13 title="Pitfall #2: Lack of consistency" subtitle="R = Requests"
```

```diff 13[25:30] title="Pitfall #2: Lack of consistency" subtitle="E = Errors (code =! 2..)"
```

```diff 10[1:2] title="Pitfall #2: Lack of consistency" subtitle="D = Duration is Missing!"
```

```go title="Pitfall #2: Consistency" subtitle="Red method satisfied"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
        requestDuration: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name:    "http_request_duration_seconds",
                Help:    "Tracks the latencies for HTTP requests.",
                Buckets: []float64{0.001, 0.01, 0.1, 0.3, 0.6, 1, 3, 6, 9, 20, 30, 60, 90, 120},
            },
            []string{"code", "method"},
        ),
	}
	reg.MustRegister(m.requestsTotal, m.requestDuration)
	return ins
}

// Top level ServerHTTP handler.
func ServerHTTP(w http.ResponseWriter, r *http.Request) {
  start := time.Now()
  defer metrics.requestDuration.WithLabelValues(statusRec.Status(), r.Method)).Observe(time.Since(start))

  statusRec := newStatusRecorder(w)
  next.ServeHTTP(statusRec, r)

  // Increment our counter with written status code and request method.
  metrics.requestsTotal.WithLabelValues(statusRec.Status(), r.Method)).Add(1)
}

```

</CodeSurfer>

<Notes>

</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #3: Not conforming naming convention</h2>

<br/>
<br/>
<ul>
<div style="font-size: 80%;">
<Appear>
<li><a href="https://prometheus.io/docs/practices/naming/#metric-and-label-naming">https://prometheus.io/docs/practices/naming/#metric-and-label-naming</a></li>
<li>
Name should have a suffix describing the unit, in plural form. Note that an accumulating count has *_total* as a suffix, in addition to the unit if applicable
Examples: <br/>
<div style="font-style: italic;">
<ul>
<li>http_request_duration_<b>seconds</b></li>
<li>node_memory_usage_<b>bytes</b></li>
<li>http_requests_<b>total</b></li>
<li>process_cpu_<b>seconds_total</b></li>
<li>build_<b>info</b></li>
</ul>
</div></li>
<li>Should have domain specific prefix (namespace e.g <b>http_</b>) for application/package.</li>
</Appear>
</div>
</ul>
<Notes>

There is official Prometheus metric and label name convention!

</Notes>

---

<CodeSurfer>

```go title="Pitfall #3: Naming: stability"

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}
```

```go title="Pitfall #3: Naming: stability" subtitle="Let's say we alert on too many 5xx responses."

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

alert: HttpErrors5xx
  expr: |
    sum(rate(http_requests_total{status=~"^5.."}[1m])) /
      sum(rate(http_requests_total[1m])) * 100 > 5
  for: 5m
  labels:
    severity: error
  annotations:
    summary: "HTTP errors 5xx (instance {{ $labels.instance }})"
    description: |
      "Too many HTTP requests with status 5xx (> 5%)\n  VALUE = {{ $value }}\n
      LABELS: {{ $labels }}"

```

```go 11[29:37] title="Pitfall #3: Naming: stability" subtitle="Let's say we are renaming metric..."

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_protocol_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

alert: HttpErrors5xx
  expr: |
    sum(rate(http_requests_total{status=~"^5.."}[1m])) /
      sum(rate(http_requests_total[1m])) * 100 > 5
  for: 5m
  labels:
    severity: error
  annotations:
    summary: "HTTP errors 5xx (instance {{ $labels.instance }})"
    description: |
      "Too many HTTP requests with status 5xx (> 5%)\n  VALUE = {{ $value }}\n
      LABELS: {{ $labels }}"

```

```go title="Pitfall #3: Naming: stability" subtitle="Ups..."

type ServerMetrics struct {
	requestsTotal    *prometheus.CounterVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	m := &ServerMetrics{
		requestsTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "http_protocol_requests_total",
				Help: "Tracks the number of HTTP requests.",
			}, []string{"code", "method"},
		),
	}
	reg.MustRegister(m.requestsTotal)
	return ins
}

## BOOM! This alert will NEVER fire but also will not fail!
## Rename can cause issues like this in Alerts, Recording rules, Dashboards and more..
alert: HttpErrors5xx
  expr: |
    sum(rate(http_requests_total{status=~"^5.."}[1m])) /
      sum(rate(http_requests_total[1m])) * 100 > 5
  for: 5m
  labels:
    severity: error
  annotations:
    summary: "HTTP errors 5xx (instance {{ $labels.instance }})"
    description: |
      "Too many HTTP requests with status 5xx (> 5%)\n  VALUE = {{ $value }}\n
      LABELS: {{ $labels }}"

```

</CodeSurfer>

<Notes>

</Notes>

---


<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #4: Unbounded Cardinality</h2>

<Notes>
	TODO: Kemal

	Add path or similar to labels
	Show bad example of passing raw error as label name of lbtransport metric for fails (!): https://github.com/observatorium/observable-demo/blob/master/pkg/lbtransport/transport.go#L38
	Why it matters, instead do as here: prepare predefine reasons: https://github.com/observatorium/observable-demo/blob/master/pkg/lbtransport/transport.go#L38.
</Notes>

---

<CodeSurfer>

```go title="Unbounded Cardinality" 7:14

type DialerMetrics struct {
	connFailedTotal      *prometheus.CounterVec
}

func NewDialerMetrics(reg prometheus.Registerer) *DialerMetrics {
	m := &DialerMetrics{
		connFailedTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Subsystem: "conntrack",
				Name:      "dialer_conn_failed_total",
				Help:      "Total number of connections failed to dial by the dialer.",
			}, []string{"reason"}),
	}

	if reg != nil {
		reg.MustRegister(m.connClosedTotal)
	}

	return m
}

```

```go 24:28

type DialerMetrics struct {
	connFailedTotal      *prometheus.CounterVec
}

func NewDialerMetrics(reg prometheus.Registerer) *DialerMetrics {
	m := &DialerMetrics{
		connFailedTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Subsystem: "conntrack",
				Name:      "dialer_conn_failed_total",
				Help:      "Total number of connections failed to dial by the dialer.",
			}, []string{"reason"}),
	}

	if reg != nil {
		reg.MustRegister(m.connClosedTotal)
	}

	return m
}

func dialClientConnTracker(...) (net.Conn, error) {
	conn, err := parentDialContextFunc(ctx, ntk, addr)
	if err != nil {
		metrics.connFailedTotal.WithLabelValues(err).Inc()
		return conn, err
	}

	return &clientConnTracker{...}, nil
}

```

```git
# HELP conntrack_dialer_conn_failed_total Total number of connections failed to dial by the dialer.
# TYPE conntrack_dialer_conn_failed_total counter
conntrack_dialer_conn_failed_total{reason="<nil>"} 1
conntrack_dialer_conn_failed_total{reason="lookup example.com on localhost: err..."} 1
conntrack_dialer_conn_failed_total{reason="lookup thanos.io on 8.8.8.8: err..."} 1
conntrack_dialer_conn_failed_total{reason="lookup redhat.com on localhost: err..."} 1
conntrack_dialer_conn_failed_total{reason="syscall: unimplemented EpollWait"} 1
conntrack_dialer_conn_failed_total{reason="syscall.SIGINT: series of unfortunate things happened"} 1
conntrack_dialer_conn_failed_total{reason="unix: test returned fd in TestEpoll"} 1
conntrack_dialer_conn_failed_total{reason="Invalid value for argument: client: nil"} 1
```

</CodeSurfer>

<Notes>

TODO: Kemal !!

</Notes>

---

# 😲

---


<CodeSurfer>

```go 5:11,22:25

// ...

func NewDialerMetrics(reg prometheus.Registerer) *DialerMetrics {
	m := &DialerMetrics{
		connFailedTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Subsystem: "conntrack",
				Name:      "dialer_conn_failed_total",
				Help:      "Total number of connections failed to dial by the dialer.",
			}, []string{"reason"}),
	}

	if reg != nil {
		reg.MustRegister(m.connClosedTotal)
	}

	return m
}

func dialClientConnTracker(...) (net.Conn, error) {
	conn, err := parentDialContextFunc(ctx, ntk, addr)
	if err != nil {
		metrics.connFailedTotal.WithLabelValues(err).Inc()
		return conn, err
	}

	return &clientConnTracker{...}, nil
}

```

```go

const (
	failedResolution  = "resolution"
	failedConnRefused = "refused"
	failedTimeout     = "timeout"
	failedUnknown     = "unknown"
)

// ...

func NewDialerMetrics(reg prometheus.Registerer) *DialerMetrics {
	m := &DialerMetrics{
		connFailedTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Subsystem: "conntrack",
				Name:      "dialer_conn_failed_total",
				Help:      "Total number of connections failed to dial by the dialer.",
			}, []string{"reason"}),
	}

	if reg != nil {
		reg.MustRegister(m.connClosedTotal)
	}

	return m
}

func dialClientConnTracker(...) (net.Conn, error) {
	conn, err := parentDialContextFunc(ctx, ntk, addr)
	if err != nil {
		metrics.connFailedTotal.WithLabelValues(err).Inc()
		return conn, err
	}

	return &clientConnTracker{...}, nil
}

```


```go

const (
	failedResolution  = "resolution"
	failedConnRefused = "refused"
	failedTimeout     = "timeout"
	failedUnknown     = "unknown"
)

// ...

func NewDialerMetrics(reg prometheus.Registerer) *DialerMetrics {
	m := &DialerMetrics{
		connFailedTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Subsystem: "conntrack",
				Name:      "dialer_conn_failed_total",
				Help:      "Total number of connections failed to dial by the dialer.",
			}, []string{"reason"}),
	}

	if reg != nil {
		reg.MustRegister(m.connClosedTotal)
	}

	return m
}

func dialClientConnTracker(...) (net.Conn, error) {
	conn, err := parentDialContextFunc(ctx, ntk, addr)
	if err != nil {
		metrics.connFailedTotal.WithLabelValues(dialErrToReason(err)).Inc()
		return conn, err
	}

	return &clientConnTracker{...}, nil
}

```

```go

const (
	failedResolution  = "resolution"
	failedConnRefused = "refused"
	failedTimeout     = "timeout"
	failedUnknown     = "unknown"
)

// ...

func NewDialerMetrics(reg prometheus.Registerer) *DialerMetrics {
	m := &DialerMetrics{
		connFailedTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Subsystem: "conntrack",
				Name:      "dialer_conn_failed_total",
				Help:      "Total number of connections failed to dial by the dialer.",
			}, []string{"reason"}),
	}

	if reg != nil {
		reg.MustRegister(m.connClosedTotal)
	}

	return m
}

func dialClientConnTracker(...) (net.Conn, error) {
	conn, err := parentDialContextFunc(ctx, ntk, addr)
	if err != nil {
		metrics.connFailedTotal.WithLabelValues(dialErrToReason(err)).Inc()
		return conn, err
	}

	return &clientConnTracker{...}, nil
}

func dialErrToReason(err error) string {
	if netErr, ok := err.(*net.OpError); ok {

		switch nestErr := netErr.Err.(type) {
		case *net.DNSError:
			return failedResolution

		case *os.SyscallError:
			if nestErr.Err == syscall.ECONNREFUSED {
				return failedConnRefused
			}
			return failedUnknown
		}

		if netErr.Timeout() {
			return failedTimeout
		}
	}

	return failedUnknown
}

```

```go 42[14:27],43,46[15:50],47,49,52[9:27],53,57

const (
	failedResolution  = "resolution"
	failedConnRefused = "refused"
	failedTimeout     = "timeout"
	failedUnknown     = "unknown"
)

// ...

func NewDialerMetrics(reg prometheus.Registerer) *DialerMetrics {
	m := &DialerMetrics{
		connFailedTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Subsystem: "conntrack",
				Name:      "dialer_conn_failed_total",
				Help:      "Total number of connections failed to dial by the dialer.",
			}, []string{"reason"}),
	}

	if reg != nil {
		reg.MustRegister(m.connClosedTotal)
	}

	return m
}

func dialClientConnTracker(...) (net.Conn, error) {
	conn, err := parentDialContextFunc(ctx, ntk, addr)
	if err != nil {
		metrics.connFailedTotal.WithLabelValues(dialErrToReason(err)).Inc()
		return conn, err
	}

	return &clientConnTracker{...}, nil
}

func dialErrToReason(err error) string {
	if netErr, ok := err.(*net.OpError); ok {

		switch nestErr := netErr.Err.(type) {
		case *net.DNSError:
			return failedResolution

		case *os.SyscallError:
			if nestErr.Err == syscall.ECONNREFUSED {
				return failedConnRefused
			}
			return failedUnknown
		}

		if netErr.Timeout() {
			return failedTimeout
		}
	}

	return failedUnknown
}

```

</CodeSurfer>

<Notes>
	TODO: Kemal
</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #5: Not Initialized Metrics</h2>

<Notes>
	TOOD: Kemal
	Counter Metrics are fine, CounterVec!!
</Notes>

---

<CodeSurfer>

```go title="Not initializing Metrics"

type DialerMetrics struct {
	connFailedTotal      *prometheus.CounterVec
}

func NewDialerMetrics(reg prometheus.Registerer) *DialerMetrics {
	m := &DialerMetrics{
		connFailedTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Subsystem: "conntrack",
				Name:      "dialer_conn_failed_total",
				Help:      "Total number of connections failed to dial by the dialer.",
			}, []string{"reason"}),
	}

	if reg != nil {
		reg.MustRegister(m.connClosedTotal)
	}

	return m
}

```

```go title="Not initializing Metrics"
m.connFailedTotal.WithLabelValues("unknown").Add(30)
```

</CodeSurfer>

<Notes>
	TODO: Kemal
</Notes>

---

import uninitialized_metrics from './static/uninitialized_metrics.png'

<Image src={uninitialized_metrics} size='contain'/>

<Notes>
	TODO: Kemal
</Notes>

---

import uninitialized_metrics_marked from './static/uninitialized_metrics_marked.png'

<Image src={uninitialized_metrics_marked} size='contain'/>

<Notes>
	TODO: Kemal
</Notes>

---

<CodeSurfer>

```go title="Not initializing Metrics"

type DialerMetrics struct {
	connFailedTotal      *prometheus.CounterVec
}

func NewDialerMetrics(reg prometheus.Registerer) *DialerMetrics {
	m := &DialerMetrics{
		connFailedTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Subsystem: "conntrack",
				Name:      "dialer_conn_failed_total",
				Help:      "Total number of connections failed to dial by the dialer.",
			}, []string{"reason"}),
	}

	if reg != nil {
		reg.MustRegister(m.connClosedTotal)
	}

	return m
}

```

```go title="Not initializing Metrics"

const (
	failedResolution  = "resolution"
	failedConnRefused = "refused"
	failedTimeout     = "timeout"
	failedUnknown     = "unknown"
)

type DialerMetrics struct {
	connFailedTotal      *prometheus.CounterVec
}

func NewDialerMetrics(reg prometheus.Registerer) *DialerMetrics {
	m := &DialerMetrics{
		connFailedTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Subsystem: "conntrack",
				Name:      "dialer_conn_failed_total",
				Help:      "Total number of connections failed to dial by the dialer.",
			}, []string{"reason"}),
	}

	if reg != nil {
		reg.MustRegister(m.connClosedTotal)
	}

	return m
}

```

```go title="Not initializing Metrics"

const (
	failedResolution  = "resolution"
	failedConnRefused = "refused"
	failedTimeout     = "timeout"
	failedUnknown     = "unknown"
)

type DialerMetrics struct {
	connFailedTotal      *prometheus.CounterVec
}

func NewDialerMetrics(reg prometheus.Registerer) *DialerMetrics {
	m := &DialerMetrics{
		connFailedTotal: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Subsystem: "conntrack",
				Name:      "dialer_conn_failed_total",
				Help:      "Total number of connections failed to dial by the dialer.",
			}, []string{"reason"}),
	}

	if reg != nil {
		reg.MustRegister(m.connClosedTotal)
	}

	// Initialize metric with labels.
	// It is possible to call this method without using the returned Counter to only
	// create the new Counter but leave it at its starting value 0.
	m.connFailedTotal.WithLabelValues(failedResolution)
	m.connFailedTotal.WithLabelValues(failedConnRefused)
	m.connFailedTotal.WithLabelValues(failedTimeout)
	m.connFailedTotal.WithLabelValues(failedUnknown)

	return m
}

```

```go title="Not initializing Metrics"
m.connFailedTotal.WithLabelValues("unknown").Add(30)
```

</CodeSurfer>

<Notes>
	TODO: Kemal

	BTW: Counters without labels are initialized without an additional step.
</Notes>

---

import initialized_metrics from './static/initialized_metrics.png'

<Image src={initialized_metrics} size='contain'/>

<Notes>
	TODO: Kemal
</Notes>

---

import initialized_metrics_marked from './static/initialized_metrics_marked.png'

<Image src={initialized_metrics_marked} size='contain'/>

<Notes>
	TODO: Kemal
</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #6: Poorly Chosen Histogram Buckets</h2>

---

<CodeSurfer>

```go title="Poorly chosen Histogram buckets"

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
				Buckets: []float64{0.001, 0.01, 0.1, 0.3, 0.6, 1, 3},
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```go title="Poorly chosen Histogram buckets" 13

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
				Buckets: []float64{0.001, 0.01, 0.1, 0.3, 0.6, 1, 3},
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```git

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.001"} 1
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.01"} 49
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.1"} 49
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.3"} 49
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.6"} 49
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="1"} 49
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="3"} 49
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="+Inf"} 49
http_request_duration_seconds_sum{code="200",handler="/metrics",method="get"} 0.11527970000000001
http_request_duration_seconds_count{code="200",handler="/metrics",method="get"} 49

```

```go title="Poorly chosen Histogram buckets" 13

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
				Buckets: []float64{0.0000001, 0.000001, 0.00001, 0.00003, 0.00006, 0.001, 0.03},
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```git

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="1e-07"} 0
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="1e-06"} 0
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="1e-05"} 0
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="3e-05"} 0
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="6e-05"} 0
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.001"} 1
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.03"} 23
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="+Inf"} 23
http_request_duration_seconds_sum{code="200",handler="/metrics",method="get"} 0.0636401
http_request_duration_seconds_count{code="200",handler="/metrics",method="get"} 23

```

```go title="Poorly chosen Histogram buckets" 13

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
				Buckets: prometheus.LinearBuckets(0.001, 0.0002, 6),
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```git

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.001"} 3
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.0012000000000000001"} 3
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.0014000000000000002"} 10
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.0016000000000000003"} 21
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.0018000000000000004"} 25
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.0020000000000000005"} 29
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="+Inf"} 49
http_request_duration_seconds_sum{code="200",handler="/metrics",method="get"} 0.10939249999999999
http_request_duration_seconds_count{code="200",handler="/metrics",method="get"} 49

```

```go title="Poorly chosen Histogram buckets"

DefaultBuckets = []float64{.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10}
prometheus.ExponentialBuckets(.1, 1.5, 5),
prometheus.LinearBuckets(.01, .01, 10)

```

</CodeSurfer>

<Notes>
	TODO: Kemal
	Show metrics with yolo many buckets
	Problem: Cardinality (explain why)
	Solution: SLO based!

	Use real life example, too large request or too small requests
	Too many buckets
	Too less buckets
</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #7: Histogram Cardinality Explosion</h2>

---

<CodeSurfer>

```go title="Histogram Cardinality Explosion"

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
				Buckets: []float64{0.001, 0.01, 0.1, 0.3, 0.6, 1, 3},
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```go title="Histogram Cardinality Explosion"

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
				Buckets: []float64{0.001, 0.01, 0.1, 0.3, 0.6, 1, 3, 6, 9, 20, 30, 60, 90, 120},
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```git

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.001"} 0
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.01"} 30
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.1"} 30
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.3"} 30
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.6"} 30
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="1"} 30
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="3"} 30
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="6"} 30
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="9"} 30
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="20"} 30
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="30"} 30
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="60"} 30
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="90"} 30
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="120"} 30
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="+Inf"} 30
http_request_duration_seconds_sum{code="200",handler="/metrics",method="get"} 0.08239999999999999
http_request_duration_seconds_count{code="200",handler="/metrics",method="get"} 30

```

```go title="Histogram Cardinality Explosion" 13

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
				Buckets: []float64{0.001, 0.01, 0.1, 0.3, 0.6, 1, 3, 6, 9, 20, 30, 40, 50, 60, 90, 120, 150, 200},
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```git

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.001"} 0
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.01"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.1"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.3"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.6"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="1"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="3"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="6"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="9"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="20"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="30"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="40"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="50"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="60"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="90"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="120"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="150"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="200"} 18
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="+Inf"} 18
http_request_duration_seconds_sum{code="200",handler="/metrics",method="get"} 0.0480237
http_request_duration_seconds_count{code="200",handler="/metrics",method="get"} 18

```

```console

➜ curl -XPOST localhost:8080/lb
localhost:8082 says hello! (:

```

</CodeSurfer>

---

# 💥

<Notes>
	TODO: Kemal
	Show metrics with yolo many buckets
	Problem: Cardinality (explain why)
	Solution: SLO based!

	Use real life example, too large request or too small requests
	Too many buckets
	Too less buckets
</Notes>

---

<CodeSurfer>

```git

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="0.001"} 0
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="0.01"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="0.1"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="0.3"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="0.6"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="1"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="3"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="6"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="9"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="20"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="30"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="40"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="50"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="60"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="90"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="120"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="150"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="200"} 2
http_request_duration_seconds_bucket{code="200",handler="/lb",method="post",le="+Inf"} 2
http_request_duration_seconds_sum{code="200",handler="/lb",method="post"} 0.0026940999999999996
http_request_duration_seconds_count{code="200",handler="/lb",method="post"} 2
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.001"} 0
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.01"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.1"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.3"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.6"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="1"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="3"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="6"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="9"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="20"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="30"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="40"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="50"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="60"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="90"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="120"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="150"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="200"} 146
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="+Inf"} 146
http_request_duration_seconds_sum{code="200",handler="/metrics",method="get"} 0.3082099000000001
http_request_duration_seconds_count{code="200",handler="/metrics",method="get"} 146
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="0.001"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="0.01"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="0.1"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="0.3"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="0.6"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="1"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="3"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="6"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="9"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="20"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="30"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="40"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="50"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="60"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="90"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="120"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="150"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="200"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-500-sometimes",method="post",le="+Inf"} 1
http_request_duration_seconds_sum{code="200",handler="demo-500-sometimes",method="post"} 4.01e-05
http_request_duration_seconds_count{code="200",handler="demo-500-sometimes",method="post"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="0.001"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="0.01"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="0.1"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="0.3"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="0.6"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="1"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="3"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="6"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="9"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="20"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="30"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="40"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="50"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="60"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="90"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="120"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="150"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="200"} 1
http_request_duration_seconds_bucket{code="200",handler="demo-refused-conn-sometimes",method="post",le="+Inf"} 1
http_request_duration_seconds_sum{code="200",handler="demo-refused-conn-sometimes",method="post"} 4.46e-05
http_request_duration_seconds_count{code="200",handler="demo-refused-conn-sometimes",method="post"} 1

```

</CodeSurfer>

---

<Image src={ss_tsdb_01} size='contain'/>

<Notes>

TODO: Kemal !!

Promdash head cardinality screeen

</Notes>

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #8: Histogram vs Summary</h2>

---

<CodeSurfer>

```go title="Histogram vs Summary"

type ServerMetrics struct {
	requestDuration  *prometheus.HistogramVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "http_request_duration_seconds",
				Help:    "Tracks the latencies for HTTP requests.",
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```git

http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.005"} 58
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.01"} 71
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.025"} 75
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.05"} 80
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.1"} 80
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.25"} 81
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="0.5"} 82
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="1"} 82
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="2.5"} 82
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="5"} 82
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="10"} 82
http_request_duration_seconds_bucket{code="200",handler="/metrics",method="get",le="+Inf"} 82
http_request_duration_seconds_sum{code="200",handler="/metrics",method="get"} 1.0698880999999996
http_request_duration_seconds_count{code="200",handler="/metrics",method="get"} 82

```

```go title="Histogram vs Summary"

type ServerMetrics struct {
	requestDuration  *prometheus.SummaryVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewSummaryVec(
			prometheus.SummaryOpts{
				Name: "http_request_duration_seconds",
				Help: "Tracks the latencies for HTTP requests.",
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```git

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds summary
http_request_duration_seconds_sum{code="200",handler="/metrics",method="get"} 0.15244579999999996
http_request_duration_seconds_count{code="200",handler="/metrics",method="get"} 59

```

```go title="Histogram vs Summary" subtitle="Do not forget to set your objectives!"

type ServerMetrics struct {
	requestDuration  *prometheus.SummaryVec
}

// NewServerMetrics provides ServerMetrics.
func NewServerMetrics(reg prometheus.Registerer) *ServerMetrics {
	ins := &ServerMetrics{
		requestDuration: prometheus.NewSummaryVec(
			prometheus.SummaryOpts{
				Name: "http_request_duration_seconds",
				Help: "Tracks the latencies for HTTP requests.",
				Objectives: map[float64]float64{0.5: 0.05, 0.9: 0.01, 0.99: 0.001},
			},
			[]string{"code", "method"},
		),
	}
	reg.MustRegister(ins.requestDuration)
	return ins
}

```

```git

# HELP http_request_duration_seconds Tracks the latencies for HTTP requests.
# TYPE http_request_duration_seconds summary
http_request_duration_seconds{code="200",handler="/metrics",method="get",quantile="0.5"} 0.0018995
http_request_duration_seconds{code="200",handler="/metrics",method="get",quantile="0.9"} 0.0054216
http_request_duration_seconds{code="200",handler="/metrics",method="get",quantile="0.99"} 0.009909
http_request_duration_seconds_sum{code="200",handler="/metrics",method="get"} 0.0775536
http_request_duration_seconds_count{code="200",handler="/metrics",method="get"} 28

```

</CodeSurfer>

<Notes>
	TODO: Kemal
	Using summary where histogram would be cheaper, explain differences
</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Pitfall #9: No Testing</h2>

---

<CodeSurfer>

```go title="Not testing"

type Metrics struct {
	successes prometheus.Counter
	failures  *prometheus.CounterVec
	duration  prometheus.Histogram
}

func NewMetrics(reg prometheus.Registerer) *Metrics {
	m := &Metrics{
		successes: prometheus.NewCounter(prometheus.CounterOpts{
			Subsystem: "lbtransport",
			Name:      "proxied_requests_total",
			Help:      "Total number successful proxy round trips.",
		}),
		failures: prometheus.NewCounterVec(prometheus.CounterOpts{
			Subsystem: "lbtransport",
			Name:      "proxied_failed_requests_total",
			Help:      "Total number failed proxy round trips.",
		}, []string{"reason"}),
		duration: prometheus.NewHistogram(
			prometheus.HistogramOpts{
				Subsystem: "lbtransport",
				Name:      "proxy_duration_seconds",
				Help:      "Duration of proxy logic.",
				Buckets:   []float64{0.001, 0.01, 0.1, 0.3, 0.6, 1, 3, 10},
			}),
	}

	if reg != nil {
		reg.MustRegister(m.successes, m.failures, m.duration)
	}

	return m
}

```

```go title="prometheus/testutil here to help"

import (
	"github.com/prometheus/client_golang/prometheus/testutil"
)

```
</CodeSurfer>

---

<CodeSurfer>

```go title="Not Testing"

struct {
	targets   []string
	responses []response
	excluded  []string

	expectedHost string
	expectedErr  error

	failedNoTargetAvailable float64
	failedNoTargetResolved  float64
	failedUnknown           float64
	successes               float64
}

```

```go title="Not Testing"

for _, tcase := range []struct {
	targets   []string
	responses []response
	excluded  []string

	expectedHost string
	expectedErr  error

	failedNoTargetAvailable float64
	failedNoTargetResolved  float64
	failedUnknown           float64
	successes               float64
}{
	// ...
} {
	if ok := t.Run("", func(t *testing.T) {
		reset(tcase)

		// ...
	}); !ok {
		return
	}
}

```

```go title="Not Testing"

for _, tcase := range []struct {
	targets   []string
	responses []response
	excluded  []string

	expectedHost string
	expectedErr  error

	failedNoTargetAvailable float64
	failedNoTargetResolved  float64
	failedUnknown           float64
	successes               float64
}{
	// ...
} {
	if ok := t.Run("", func(t *testing.T) {
		reset(tcase)

		resp, err := lb.RoundTrip(httptest.NewRequest("GET", "http://whatever", nil))
		if tcase.expectedErr != nil {
			testutil.NotOk(t, err)
			testutil.Equals(t, tcase.expectedErr.Error(), err.Error())
		} else {
			testutil.Ok(t, err)
			testutil.Equals(t, tcase.expectedHost, resp.Request.URL.Host)
		}
	}); !ok {
		return
	}
}

```

```go title="Not Testing" 15:21,25:33,34[5:7]

for _, tcase := range []struct {
	targets   []string
	responses []response
	excluded  []string

	expectedHost string
	expectedErr  error

	failedNoTargetAvailable float64
	failedNoTargetResolved  float64
	failedUnknown           float64
	successes               float64
}{
	{
		targets:      []string{"a"},
		responses:    []response{okResponse("a")},
		expectedHost: "a",

		successes: 1,
	},
} {
	if ok := t.Run("", func(t *testing.T) {
		reset(tcase)

		resp, err := lb.RoundTrip(httptest.NewRequest("GET", "http://whatever", nil))
		if tcase.expectedErr != nil {
			testutil.NotOk(t, err)
			testutil.Equals(t, tcase.expectedErr.Error(), err.Error())
		} else {
			testutil.Ok(t, err)
			testutil.Equals(t, tcase.expectedHost, resp.Request.URL.Host)
		}
	}); !ok {
		return
	}
}

```

```go title="Not Testing"

for _, tcase := range []struct {
	targets   []string
	responses []response
	excluded  []string

	expectedHost string
	expectedErr  error

	failedNoTargetAvailable float64
	failedNoTargetResolved  float64
	failedUnknown           float64
	successes               float64
}{
	{
		targets:      []string{"a"},
		responses:    []response{okResponse("a")},
		expectedHost: "a",

		successes: 1,
	},
} {
	if ok := t.Run("", func(t *testing.T) {
		reset(tcase)

		resp, err := lb.RoundTrip(httptest.NewRequest("GET", "http://whatever", nil))
		if tcase.expectedErr != nil {
			testutil.NotOk(t, err)
			testutil.Equals(t, tcase.expectedErr.Error(), err.Error())
		} else {
			testutil.Ok(t, err)
			testutil.Equals(t, tcase.expectedHost, resp.Request.URL.Host)
		}
		testutil.Equals(t, tcase.excluded, picker.excluded)
		testutil.Equals(t, discovery.Targets(), picker.lastSeenTargets)
	}); !ok {
		return
	}
}

```

```go title="Not Testing"

for _, tcase := range []struct {
	targets   []string
	responses []response
	excluded  []string

	expectedHost string
	expectedErr  error

	failedNoTargetAvailable float64
	failedNoTargetResolved  float64
	failedUnknown           float64
	successes               float64
}{
	{
		targets:      []string{"a"},
		responses:    []response{okResponse("a")},
		expectedHost: "a",

		successes: 1,
	},
} {
	if ok := t.Run("", func(t *testing.T) {
		reset(tcase)

		resp, err := lb.RoundTrip(httptest.NewRequest("GET", "http://whatever", nil))
		if tcase.expectedErr != nil {
			testutil.NotOk(t, err)
			testutil.Equals(t, tcase.expectedErr.Error(), err.Error())
		} else {
			testutil.Ok(t, err)
			testutil.Equals(t, tcase.expectedHost, resp.Request.URL.Host)
		}
		testutil.Equals(t, tcase.excluded, picker.excluded)
		testutil.Equals(t, discovery.Targets(), picker.lastSeenTargets)

		testutil.Equals(t, tcase.successes, promtestutil.ToFloat64(metrics.successes))
		testutil.Equals(t, tcase.failedNoTargetAvailable, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedNoTargetAvailable)))
		testutil.Equals(t, tcase.failedNoTargetResolved, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedNoTargetResolved)))
		testutil.Equals(t, tcase.failedUnknown, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedUnknown)))
		testutil.Equals(t, float64(0), promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedTimeout)))
		testutil.Equals(t, 4, promtestutil.CollectAndCount(lb.metrics.failures))
	}); !ok {
		return
	}
}

```

```go title="Not Testing"

for _, tcase := range []struct {
	targets   []string
	responses []response
	excluded  []string

	expectedHost string
	expectedErr  error

	failedNoTargetAvailable float64
	failedNoTargetResolved  float64
	failedUnknown           float64
	successes               float64
}{
	{
		targets:      []string{"a"},
		responses:    []response{okResponse("a")},
		expectedHost: "a",

		successes: 1,
	},
} {
	if ok := t.Run("", func(t *testing.T) {
		reset(tcase)

		resp, err := lb.RoundTrip(httptest.NewRequest("GET", "http://whatever", nil))
		if tcase.expectedErr != nil {
			testutil.NotOk(t, err)
			testutil.Equals(t, tcase.expectedErr.Error(), err.Error())
		} else {
			testutil.Ok(t, err)
			testutil.Equals(t, tcase.expectedHost, resp.Request.URL.Host)
		}
		testutil.Equals(t, tcase.excluded, picker.excluded)
		testutil.Equals(t, discovery.Targets(), picker.lastSeenTargets)

		testutil.Equals(t, tcase.successes, promtestutil.ToFloat64(metrics.successes))
		testutil.Equals(t, tcase.failedNoTargetAvailable, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedNoTargetAvailable)))
		testutil.Equals(t, tcase.failedNoTargetResolved, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedNoTargetResolved)))
		testutil.Equals(t, tcase.failedUnknown, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedUnknown)))
		testutil.Equals(t, float64(0), promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedTimeout)))
		testutil.Equals(t, 4, promtestutil.CollectAndCount(lb.metrics.failures))
	}); !ok {
		return
	}
}

```

```go title="Not Testing"

for _, tcase := range []struct {
	targets   []string
	responses []response
	excluded  []string

	expectedHost string
	expectedErr  error

	failedNoTargetAvailable float64
	failedNoTargetResolved  float64
	failedUnknown           float64
	successes               float64
}{
	{
		targets:      []string{"a"},
		responses:    []response{okResponse("a")},
		expectedHost: "a",

		successes: 1,
	},
	{
		targets: []string{"a"},
		responses: []response{
			{host: "a", err: &net.OpError{Op: "dial", Err: syscall.ECONNREFUSED}},
		},
		excluded:    []string{"a"},
		expectedErr: errors.New("lb: no target is available"),

		successes: 2, failedNoTargetAvailable: 1,
	},
} {
	if ok := t.Run("", func(t *testing.T) {
		reset(tcase)

		resp, err := lb.RoundTrip(httptest.NewRequest("GET", "http://whatever", nil))
		if tcase.expectedErr != nil {
			testutil.NotOk(t, err)
			testutil.Equals(t, tcase.expectedErr.Error(), err.Error())
		} else {
			testutil.Ok(t, err)
			testutil.Equals(t, tcase.expectedHost, resp.Request.URL.Host)
		}
		testutil.Equals(t, tcase.excluded, picker.excluded)
		testutil.Equals(t, discovery.Targets(), picker.lastSeenTargets)

		testutil.Equals(t, tcase.successes, promtestutil.ToFloat64(metrics.successes))
		testutil.Equals(t, tcase.failedNoTargetAvailable, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedNoTargetAvailable)))
		testutil.Equals(t, tcase.failedNoTargetResolved, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedNoTargetResolved)))
		testutil.Equals(t, tcase.failedUnknown, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedUnknown)))
		testutil.Equals(t, float64(0), promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedTimeout)))
		testutil.Equals(t, 4, promtestutil.CollectAndCount(lb.metrics.failures))
	}); !ok {
		return
	}
}

```

```go title="Not Testing"

for _, tcase := range []struct {
	targets   []string
	responses []response
	excluded  []string

	expectedHost string
	expectedErr  error

	failedNoTargetAvailable float64
	failedNoTargetResolved  float64
	failedUnknown           float64
	successes               float64
}{
	{
		targets:      []string{"a"},
		responses:    []response{okResponse("a")},
		expectedHost: "a",

		successes: 1,
	},
	{
		targets: []string{"a"},
		responses: []response{
			{host: "a", err: &net.OpError{Op: "dial", Err: syscall.ECONNREFUSED}},
		},
		excluded:    []string{"a"},
		expectedErr: errors.New("lb: no target is available"),

		successes: 2, failedNoTargetAvailable: 1,
	},
	{
		targets:     []string{},
		expectedErr: errors.New("lb: no target was resolved"),

		successes: 2, failedNoTargetAvailable: 1, failedNoTargetResolved: 1,
	},
} {
	if ok := t.Run("", func(t *testing.T) {
		reset(tcase)

		resp, err := lb.RoundTrip(httptest.NewRequest("GET", "http://whatever", nil))
		if tcase.expectedErr != nil {
			testutil.NotOk(t, err)
			testutil.Equals(t, tcase.expectedErr.Error(), err.Error())
		} else {
			testutil.Ok(t, err)
			testutil.Equals(t, tcase.expectedHost, resp.Request.URL.Host)
		}
		testutil.Equals(t, tcase.excluded, picker.excluded)
		testutil.Equals(t, discovery.Targets(), picker.lastSeenTargets)

		testutil.Equals(t, tcase.successes, promtestutil.ToFloat64(metrics.successes))
		testutil.Equals(t, tcase.failedNoTargetAvailable, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedNoTargetAvailable)))
		testutil.Equals(t, tcase.failedNoTargetResolved, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedNoTargetResolved)))
		testutil.Equals(t, tcase.failedUnknown, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedUnknown)))
		testutil.Equals(t, float64(0), promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedTimeout)))
		testutil.Equals(t, 4, promtestutil.CollectAndCount(lb.metrics.failures))
	}); !ok {
		return
	}
}

```

```go title="Not Testing"

for _, tcase := range []struct {
	targets   []string
	responses []response
	excluded  []string

	expectedHost string
	expectedErr  error

	failedNoTargetAvailable float64
	failedNoTargetResolved  float64
	failedUnknown           float64
	successes               float64
}{
	{
		targets:      []string{"a"},
		responses:    []response{okResponse("a")},
		expectedHost: "a",

		successes: 1,
	},
	{
		targets: []string{"a"},
		responses: []response{
			{host: "a", err: &net.OpError{Op: "dial", Err: syscall.ECONNREFUSED}},
		},
		excluded:    []string{"a"},
		expectedErr: errors.New("lb: no target is available"),

		successes: 2, failedNoTargetAvailable: 1,
	},
	{
		targets:     []string{},
		expectedErr: errors.New("lb: no target was resolved"),

		successes: 2, failedNoTargetAvailable: 1, failedNoTargetResolved: 1,
	},
	{
		targets: []string{"a", "b", "c", "d", "e", "f", "g"},
		responses: []response{
			{host: "a", err: &net.OpError{Op: "dial", Err: syscall.ECONNREFUSED}},
			{host: "b", err: &net.OpError{Op: "dial", Err: syscall.ECONNREFUSED}},
			{host: "c", err: &net.OpError{Op: "dial", Err: syscall.ECONNREFUSED}},
			{host: "d", err: &net.OpError{Op: "dial", Err: syscall.ECONNREFUSED}},
			{host: "e", err: &net.OpError{Op: "dial", Err: syscall.ECONNREFUSED}},
			{host: "f", err: &net.OpError{Op: "dial", Err: syscall.ECONNREFUSED}},
			okResponse("g"),
		},
		excluded:     []string{"a", "b", "c", "d", "e", "f"},
		expectedHost: "g",

		successes: 3, failedNoTargetAvailable: 1, failedNoTargetResolved: 1,
	},
} {
	if ok := t.Run("", func(t *testing.T) {
		reset(tcase)

		resp, err := lb.RoundTrip(httptest.NewRequest("GET", "http://whatever", nil))
		if tcase.expectedErr != nil {
			testutil.NotOk(t, err)
			testutil.Equals(t, tcase.expectedErr.Error(), err.Error())
		} else {
			testutil.Ok(t, err)
			testutil.Equals(t, tcase.expectedHost, resp.Request.URL.Host)
		}
		testutil.Equals(t, tcase.excluded, picker.excluded)
		testutil.Equals(t, discovery.Targets(), picker.lastSeenTargets)

		testutil.Equals(t, tcase.successes, promtestutil.ToFloat64(metrics.successes))
		testutil.Equals(t, tcase.failedNoTargetAvailable, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedNoTargetAvailable)))
		testutil.Equals(t, tcase.failedNoTargetResolved, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedNoTargetResolved)))
		testutil.Equals(t, tcase.failedUnknown, promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedUnknown)))
		testutil.Equals(t, float64(0), promtestutil.ToFloat64(metrics.failures.WithLabelValues(failedTimeout)))
		testutil.Equals(t, 4, promtestutil.CollectAndCount(lb.metrics.failures))
	}); !ok {
		return
	}
}

```

</CodeSurfer>

<Notes>
	TODO: Kemal
	No tests
	Solution: testutil! lbtransport metrics, reliability! Shows how you can use metrics, what behaviour to expect!

	You have some metrics to test!
	But it's hard to write tests!

	prometheus/testutil here to help
</Notes>

---

<h2 style="text-align: center; margin: 0 10px 0 10px;">Sum things Up? Summary?</h2>

---

# Summary

<ul>
	<Appear>
		<li>Pitfall #1: Global Registry</li>
		<li>Pitfall #2: Lack of Consistency</li>
		<li>Pitfall #3: Conforming Naming</li>
		<li>Pitfall #4: Unbounded Cardinality</li>
		<li>Pitfall #5: Not Initialized Metrics</li>
		<li>Pitfall #6: Poorly Chosen Histogram Buckets</li>
		<li>Pitfall #7: Histogram Cardinality Explosion</li>
		<li>Pitfall #8: Histogram vs Summary</li>
		<li>Pitfall #9: No Testing</li>
	</Appear>
</ul>

## TODO: Kemal

<Notes>
	TODO: Kemal
</Notes>

---

# Thank you!

<img src="https://raw.githubusercontent.com/kakkoyun/are-you-testing-your-observability/master/static/red_hat_white.png" style="height: 20%"/>

Reference:
* [Observable Demo](https://github.com/observatorium/observable-demo)
* [Slides](https://github.com/kakkoyun/are-you-testing-your-observability)
* [Thanos](https://thanos.io)
* [Prometheus](https://prometheus.io)
* [Prometheus - client_go](https://godoc.org/github.com/prometheus/client_golang/prometheus/testutil)
* [Prometheus - Histogram](https://prometheus.io/docs/practices/histograms/)
* [Prometheus Histograms – Past, Present, and Future](https://www.youtube.com/watch?v=7sQFkaMCyEI)
* [Roboust Perception - Cardinality is the key](https://www.robustperception.io/cardinality-is-key)
* [Gopherize me](https://gopherize.me/)
* [Why globals are magic](https://peter.bourgon.org/blog/2017/06/09/theory-of-modern-go.html)
* [Red Method](https://grafana.com/blog/2018/08/02/the-red-method-how-to-instrument-your-services/)
